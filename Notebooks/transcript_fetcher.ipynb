{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eebb32-05d1-4630-b968-7662a3b8737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"Quick manual test for fetching a transcript.\"\"\"\n",
    "    video_id = \"J8lxHyQmcaI\"  # sample video id\n",
    "    # fetcher = TranscriptFetcher()\n",
    "    # transcript = fetcher.fetch_transcript(video_id)\n",
    "    # if transcript:\n",
    "    #     print(json.dumps({\"video_id\": video_id, \"excerpt\": transcript[:500]}, indent=2))\n",
    "    # else:\n",
    "    #     sys.exit(1)\n",
    "\n",
    "    from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "    ytt_api = YouTubeTranscriptApi()\n",
    "    ytt_api.fetch(video_id, languages = [\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaec04a-488f-46fc-8ba1-42a919ec739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FetchedTranscriptSnippet(text='Did you know that Nvidia is the most', start=0.0, duration=3.36)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"Quick manual test for fetching a transcript.\"\"\"\n",
    "    video_id = \"J8lxHyQmcaI\"  # sample video id\n",
    "    # fetcher = TranscriptFetcher()\n",
    "    # transcript = fetcher.fetch_transcript(video_id)\n",
    "    # if transcript:\n",
    "    #     print(json.dumps({\"video_id\": video_id, \"excerpt\": transcript[:500]}, indent=2))\n",
    "    # else:\n",
    "    #     sys.exit(1)\n",
    "\n",
    "    from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "    ytt_api = YouTubeTranscriptApi()\n",
    "    fetched_transcript = ytt_api.fetch(video_id, languages = [\"en\"])\n",
    "    print(fetched_transcript[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5430e9d1-d37a-4b3c-b9c1-7d6a6fd2592e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchedTranscript(snippets=[FetchedTranscriptSnippet(text='Did you know that Nvidia is the most', start=0.0, duration=3.36), FetchedTranscriptSnippet(text='valuable company in the world? I mean,', start=1.36, duration=3.919), FetchedTranscriptSnippet(text='it makes sense, right? All of these huge', start=3.36, duration=3.6), FetchedTranscriptSnippet(text='AI companies are relying on them fully', start=5.279, duration=3.761), FetchedTranscriptSnippet(text='in order to do the AI stuff that we all', start=6.96, duration=3.84), FetchedTranscriptSnippet(text=\"expect them to do. That's why Nvidia's\", start=9.04, duration=4.24), FetchedTranscriptSnippet(text='value is comparable to that of silver.', start=10.8, duration=4.64), FetchedTranscriptSnippet(text='Yes, all of the silver in the world is', start=13.28, duration=4.32), FetchedTranscriptSnippet(text='comparable to the value of Nvidia, just', start=15.44, duration=4.32), FetchedTranscriptSnippet(text='one company that makes chips for gamers.', start=17.6, duration=4.0), FetchedTranscriptSnippet(text='And now those same chips turn out to be', start=19.76, duration=3.519), FetchedTranscriptSnippet(text='really good for AI stuff, which is why', start=21.6, duration=3.28), FetchedTranscriptSnippet(text='everybody is using them. So, does', start=23.279, duration=3.84), FetchedTranscriptSnippet(text=\"Anthropic, oh, Anthropic's moving to\", start=24.88, duration=4.08), FetchedTranscriptSnippet(text=\"Google's TPUs? Well, that's fine.\", start=27.119, duration=3.041), FetchedTranscriptSnippet(text=\"There's plenty of other companies that\", start=28.96, duration=3.439), FetchedTranscriptSnippet(text=\"aren't doing that like OpenAI. Oh,\", start=30.16, duration=4.64), FetchedTranscriptSnippet(text='OpenAI is partnering with Cerebrris, the', start=32.399, duration=4.0), FetchedTranscriptSnippet(text=\"chip company. Well, at least there's\", start=34.8, duration=4.96), FetchedTranscriptSnippet(text=\"Meta, right? Oh, Google's working to\", start=36.399, duration=5.361), FetchedTranscriptSnippet(text=\"erode Nvidia's software advantage with\", start=39.76, duration=4.0), FetchedTranscriptSnippet(text=\"Meta's help. Google's going to be giving\", start=41.76, duration=5.44), FetchedTranscriptSnippet(text='TPUs to Meta. Huh. Very interesting. In', start=43.76, duration=5.76), FetchedTranscriptSnippet(text='fact, things have gotten so crazy that', start=47.2, duration=4.4), FetchedTranscriptSnippet(text='even Nvidia is investing in alternatives', start=49.52, duration=4.08), FetchedTranscriptSnippet(text='to Nvidia, like Grock, who they just', start=51.6, duration=3.599), FetchedTranscriptSnippet(text=\"paid some crazy number. It's currently\", start=53.6, duration=4.4), FetchedTranscriptSnippet(text='estimated around $20 billion to license', start=55.199, duration=4.561), FetchedTranscriptSnippet(text=\"Grock's technology and pull its founder\", start=58.0, duration=3.76), FetchedTranscriptSnippet(text='and some other people over to bring what', start=59.76, duration=4.08), FetchedTranscriptSnippet(text='Grock does to Nvidia because it turns', start=61.76, duration=5.12), FetchedTranscriptSnippet(text='out GPUs might not actually be the best', start=63.84, duration=5.279), FetchedTranscriptSnippet(text=\"solution for AI going forward. It's\", start=66.88, duration=3.919), FetchedTranscriptSnippet(text='crazy to think that the literal most', start=69.119, duration=3.841), FetchedTranscriptSnippet(text='valuable company in the world might be', start=70.799, duration=4.081), FetchedTranscriptSnippet(text='selling a type of chip that stops being', start=72.96, duration=3.92), FetchedTranscriptSnippet(text='relevant in the next few years, if not', start=74.88, duration=4.559), FetchedTranscriptSnippet(text='even few months. And I have a lot to say', start=76.88, duration=3.919), FetchedTranscriptSnippet(text=\"about it. But you know what's likely\", start=79.439, duration=3.761), FetchedTranscriptSnippet(text=\"going to stay valuable? Today's sponsor.\", start=80.799, duration=4.081), FetchedTranscriptSnippet(text=\"One of the biggest hiccups I've seen for\", start=83.2, duration=3.84), FetchedTranscriptSnippet(text='big companies adopting AI tools is the', start=84.88, duration=4.16), FetchedTranscriptSnippet(text='change in the mindset and flow. A lot of', start=87.04, duration=3.68), FetchedTranscriptSnippet(text=\"their stuff just isn't built for moving\", start=89.04, duration=4.16), FetchedTranscriptSnippet(text='this fast. In particular, their CI. How', start=90.72, duration=4.56), FetchedTranscriptSnippet(text='great is it to file 10 PRs a day if', start=93.2, duration=4.239), FetchedTranscriptSnippet(text='those PRs take 40 minutes each to build?', start=95.28, duration=3.6), FetchedTranscriptSnippet(text='Be a lot better if they took under a', start=97.439, duration=3.281), FetchedTranscriptSnippet(text='minute, right? That sounds impossible', start=98.88, duration=3.199), FetchedTranscriptSnippet(text=\"though. Unless you're using today's\", start=100.72, duration=3.28), FetchedTranscriptSnippet(text='sponsor, Depot. These guys will make', start=102.079, duration=4.961), FetchedTranscriptSnippet(text='your builds absurdly fast. Post Hog got', start=104.0, duration=6.24), FetchedTranscriptSnippet(text='30 times faster. Their builds went from', start=107.04, duration=6.719), FetchedTranscriptSnippet(text=\"138 minutes down to 4 and a half. That's\", start=110.24, duration=6.879), FetchedTranscriptSnippet(text='hilariously faster. Even the worst case', start=113.759, duration=6.561), FetchedTranscriptSnippet(text='with Zed still saw a 1.4x increase. Most', start=117.119, duration=5.441), FetchedTranscriptSnippet(text='saw closer to 3 to 20x though with', start=120.32, duration=5.52), FetchedTranscriptSnippet(text='Mastadon hitting 19x from 46 minutes to', start=122.56, duration=5.6), FetchedTranscriptSnippet(text='2 1/2. I like how Post Hog put this', start=125.84, duration=4.88), FetchedTranscriptSnippet(text='best. Around here, we say Post Hog ships', start=128.16, duration=4.56), FetchedTranscriptSnippet(text=\"weirdly fast. And you can't say Post Hog\", start=130.72, duration=3.599), FetchedTranscriptSnippet(text=\"ships weirdly fast if you're waiting for\", start=132.72, duration=4.0), FetchedTranscriptSnippet(text='an hour and 45 minutes for it to ship. I', start=134.319, duration=3.761), FetchedTranscriptSnippet(text='personally experienced this when we were', start=136.72, duration=3.12), FetchedTranscriptSnippet(text='trying to ship changes on T3 chat for', start=138.08, duration=3.68), FetchedTranscriptSnippet(text='our wrapped feature and Post Hog was', start=139.84, duration=3.52), FetchedTranscriptSnippet(text='shipping stuff for us. They got things', start=141.76, duration=3.68), FetchedTranscriptSnippet(text='shipped during a holiday week in', start=143.36, duration=4.0), FetchedTranscriptSnippet(text='literally 10 minutes because their', start=145.44, duration=4.08), FetchedTranscriptSnippet(text='builds finished almost instantly because', start=147.36, duration=4.32), FetchedTranscriptSnippet(text='they moved depot. Depot unblocked', start=149.52, duration=4.4), FetchedTranscriptSnippet(text=\"features for me. That's something I\", start=151.68, duration=4.559), FetchedTranscriptSnippet(text=\"can't say about very many sponsors. It's\", start=153.92, duration=4.16), FetchedTranscriptSnippet(text='time to stop wasting time. Fix your', start=156.239, duration=4.241), FetchedTranscriptSnippet(text='builds at soyv.link/depo.', start=158.08, duration=4.64), FetchedTranscriptSnippet(text=\"So, let's talk a bit about why Nvidia's\", start=160.48, duration=4.479), FetchedTranscriptSnippet(text='kind of doomed. In order to understand', start=162.72, duration=4.0), FetchedTranscriptSnippet(text='this, we need to first understand how we', start=164.959, duration=3.92), FetchedTranscriptSnippet(text='got here in the first place. Why is it', start=166.72, duration=3.76), FetchedTranscriptSnippet(text='that the company that made graphics', start=168.879, duration=4.72), FetchedTranscriptSnippet(text='cards for our gaming PCs suddenly became', start=170.48, duration=5.68), FetchedTranscriptSnippet(text='the most valuable company in the world?', start=173.599, duration=4.321), FetchedTranscriptSnippet(text='I could go way too deep on the weird', start=176.16, duration=4.32), FetchedTranscriptSnippet(text='history of Nvidia as a hardware partner', start=177.92, duration=5.2), FetchedTranscriptSnippet(text='from how they [\\xa0__\\xa0] over Apple, so many', start=180.48, duration=4.16), FetchedTranscriptSnippet(text=\"other things. I just I'm a nerd about\", start=183.12, duration=3.36), FetchedTranscriptSnippet(text='this. I know way too much. I have been', start=184.64, duration=4.0), FetchedTranscriptSnippet(text='an Nvidia hater for the better part of', start=186.48, duration=4.479), FetchedTranscriptSnippet(text='like 15 or so years now because they', start=188.64, duration=4.879), FetchedTranscriptSnippet(text='made my life as a PC builder way harder.', start=190.959, duration=4.241), FetchedTranscriptSnippet(text=\"They made Apple's lives way harder. They\", start=193.519, duration=3.761), FetchedTranscriptSnippet(text=\"Nvidia's just been a really bad player\", start=195.2, duration=5.119), FetchedTranscriptSnippet(text='in the market for a long, long time. But', start=197.28, duration=5.52), FetchedTranscriptSnippet(text='Nvidia did have one thing, the best', start=200.319, duration=5.601), FetchedTranscriptSnippet(text='GPUs. It turns out making GPUs is hard.', start=202.8, duration=4.96), FetchedTranscriptSnippet(text=\"That's why so many companies have been\", start=205.92, duration=4.399), FetchedTranscriptSnippet(text='struggling to get into it themselves.', start=207.76, duration=4.399), FetchedTranscriptSnippet(text='Intel started their own GPU division a', start=210.319, duration=3.761), FetchedTranscriptSnippet(text='few years ago in order to try and catch', start=212.159, duration=4.16), FetchedTranscriptSnippet(text='up with Nvidia and AMD and they have', start=214.08, duration=4.879), FetchedTranscriptSnippet(text='struggled immensely. AMD tried and', start=216.319, duration=4.401), FetchedTranscriptSnippet(text='failed as well and instead chose to buy', start=218.959, duration=3.441), FetchedTranscriptSnippet(text='out ATI which was a company that was', start=220.72, duration=3.28), FetchedTranscriptSnippet(text='competing pretty close with Nvidia at', start=222.4, duration=3.52), FetchedTranscriptSnippet(text='the time, the time being like 20 years', start=224.0, duration=4.4), FetchedTranscriptSnippet(text='ago and since then has been folded fully', start=225.92, duration=4.56), FetchedTranscriptSnippet(text='into AMD as their graphics division. And', start=228.4, duration=3.68), FetchedTranscriptSnippet(text='those graphics chips are the ones being', start=230.48, duration=3.759), FetchedTranscriptSnippet(text='used in most home consoles today. Things', start=232.08, duration=3.92), FetchedTranscriptSnippet(text='like the Xbox and the PlayStation', start=234.239, duration=3.92), FetchedTranscriptSnippet(text='because both Sony and Microsoft have', start=236.0, duration=3.76), FetchedTranscriptSnippet(text='moved as far away from Nvidia as', start=238.159, duration=3.44), FetchedTranscriptSnippet(text=\"possible because they've had so many\", start=239.76, duration=3.679), FetchedTranscriptSnippet(text='problems with them. And funny enough,', start=241.599, duration=3.92), FetchedTranscriptSnippet(text='the only one still betting on Nvidia for', start=243.439, duration=4.0), FetchedTranscriptSnippet(text='consoles is Nintendo because they inked', start=245.519, duration=4.08), FetchedTranscriptSnippet(text='some crazy private deal in order to use', start=247.439, duration=4.561), FetchedTranscriptSnippet(text=\"all of Nvidia's failed ARM chips that\", start=249.599, duration=4.081), FetchedTranscriptSnippet(text='they were trying to sell for tablets,', start=252.0, duration=3.12), FetchedTranscriptSnippet(text='trying to move those to the Switch in', start=253.68, duration=2.799), FetchedTranscriptSnippet(text='hopes of finding a market for it. And', start=255.12, duration=2.799), FetchedTranscriptSnippet(text='that went better than anyone would have', start=256.479, duration=3.921), FetchedTranscriptSnippet(text=\"expected. So Nvidia's only console\", start=257.919, duration=5.041), FetchedTranscriptSnippet(text='sales, only gaming sales right now are', start=260.4, duration=4.32), FetchedTranscriptSnippet(text='to Nintendo of all companies. But for', start=262.96, duration=3.92), FetchedTranscriptSnippet(text='the most part, Nvidia has pissed off all', start=264.72, duration=4.16), FetchedTranscriptSnippet(text='of their partners over the last 20 years', start=266.88, duration=3.68), FetchedTranscriptSnippet(text='to the point where very few of them', start=268.88, duration=4.16), FetchedTranscriptSnippet(text='still choose to rely heavily on Nvidia', start=270.56, duration=4.8), FetchedTranscriptSnippet(text='in the hardware sales and distribution', start=273.04, duration=3.84), FetchedTranscriptSnippet(text='space. And the reason they get away with', start=275.36, duration=3.92), FetchedTranscriptSnippet(text='it is again making GPUs is really,', start=276.88, duration=4.56), FetchedTranscriptSnippet(text=\"really hard. It's so hard that Nvidia\", start=279.28, duration=3.76), FetchedTranscriptSnippet(text=\"doesn't even do it themselves. So what\", start=281.44, duration=3.6), FetchedTranscriptSnippet(text='the hell makes Nvidia so valuable then', start=283.04, duration=4.24), FetchedTranscriptSnippet(text=\"if they're not making the GPUs? company\", start=285.04, duration=3.92), FetchedTranscriptSnippet(text=\"that's actually making the chips and the\", start=287.28, duration=3.359), FetchedTranscriptSnippet(text='dyes and the silicon that goes into', start=288.96, duration=4.56), FetchedTranscriptSnippet(text=\"Nvidia's GPUs is a company named TSMC,\", start=290.639, duration=4.881), FetchedTranscriptSnippet(text=\"Taiwan's semiconductor manufacturing\", start=293.52, duration=3.92), FetchedTranscriptSnippet(text='company. These guys manufacture the', start=295.52, duration=4.0), FetchedTranscriptSnippet(text='silicon for all of the best chips in the', start=297.44, duration=3.84), FetchedTranscriptSnippet(text='world. There are other companies that', start=299.52, duration=3.84), FetchedTranscriptSnippet(text='make chips, but none of them make chips', start=301.28, duration=5.52), FetchedTranscriptSnippet(text='as small, refined, and powerful as TSMC.', start=303.36, duration=5.119), FetchedTranscriptSnippet(text=\"That's why Apple relies on them heavily\", start=306.8, duration=3.92), FetchedTranscriptSnippet(text='for all of their chips. The reason the M', start=308.479, duration=4.56), FetchedTranscriptSnippet(text='series Maxs and the iPhones and iPads in', start=310.72, duration=4.0), FetchedTranscriptSnippet(text='general are so performant is because', start=313.039, duration=4.081), FetchedTranscriptSnippet(text='Apple made a bet on TSMC early as their', start=314.72, duration=4.24), FetchedTranscriptSnippet(text='silicon manufacturing partner. And more', start=317.12, duration=3.44), FetchedTranscriptSnippet(text='and more companies have had to move over', start=318.96, duration=3.44), FetchedTranscriptSnippet(text='as well, including crazy enough', start=320.56, duration=3.359), FetchedTranscriptSnippet(text='companies like Intel that historically', start=322.4, duration=3.76), FetchedTranscriptSnippet(text='have owned their own manufacturing. TSMC', start=323.919, duration=4.72), FetchedTranscriptSnippet(text='is in my opinion the company that is', start=326.16, duration=5.28), FetchedTranscriptSnippet(text='actually most valuable by far across all', start=328.639, duration=5.28), FetchedTranscriptSnippet(text='of this because without TSMC the', start=331.44, duration=4.4), FetchedTranscriptSnippet(text='performance that we expect from Nvidia,', start=333.919, duration=4.0), FetchedTranscriptSnippet(text='from AMD, from Intel, from Apple, from', start=335.84, duration=4.079), FetchedTranscriptSnippet(text='all these things is no longer possible.', start=337.919, duration=3.921), FetchedTranscriptSnippet(text='This company is what the next world war', start=339.919, duration=3.921), FetchedTranscriptSnippet(text='will probably start around. As crazy as', start=341.84, duration=4.4), FetchedTranscriptSnippet(text='that sounds, whoever controls TSMC kind', start=343.84, duration=4.32), FetchedTranscriptSnippet(text='of controls how powerful chips are for', start=346.24, duration=4.239), FetchedTranscriptSnippet(text='the rest of the world. But TSMC is just', start=348.16, duration=4.16), FetchedTranscriptSnippet(text='taking a blueprint and constructing it.', start=350.479, duration=3.361), FetchedTranscriptSnippet(text='Those blueprints have to come from', start=352.32, duration=3.2), FetchedTranscriptSnippet(text='companies. Those specs, those plans,', start=353.84, duration=3.28), FetchedTranscriptSnippet(text='those tolerances, those expectations,', start=355.52, duration=4.16), FetchedTranscriptSnippet(text='the SDKs and platforms around them, the', start=357.12, duration=3.919), FetchedTranscriptSnippet(text=\"thing that you're actually shipping to a\", start=359.68, duration=3.6), FetchedTranscriptSnippet(text=\"user. TSMC isn't shipping a chip to a\", start=361.039, duration=4.481), FetchedTranscriptSnippet(text='user. TSMC is taking in a blueprint,', start=363.28, duration=4.16), FetchedTranscriptSnippet(text='printing it onto an impossibly small', start=365.52, duration=3.76), FetchedTranscriptSnippet(text='die, and then sending that to a company', start=367.44, duration=3.52), FetchedTranscriptSnippet(text='like Apple or Nvidia to do what they', start=369.28, duration=3.919), FetchedTranscriptSnippet(text='want to with. And Nvidia has really,', start=370.96, duration=5.12), FetchedTranscriptSnippet(text='really good architecture for doing GPUs', start=373.199, duration=4.481), FetchedTranscriptSnippet(text='through processes being developed by', start=376.08, duration=4.88), FetchedTranscriptSnippet(text='TSMC. Nvidia comes up with crazy ways to', start=377.68, duration=5.519), FetchedTranscriptSnippet(text='do compute with silicon that they then', start=380.96, duration=4.4), FetchedTranscriptSnippet(text='forward to TSMC as a plan that gets', start=383.199, duration=3.44), FetchedTranscriptSnippet(text='manufactured and then given back to', start=385.36, duration=2.88), FetchedTranscriptSnippet(text='Nvidia. And part of the agreement is', start=386.639, duration=3.84), FetchedTranscriptSnippet(text=\"that TSMC can't keep those blueprints,\", start=388.24, duration=3.84), FetchedTranscriptSnippet(text=\"can't reuse or sell those blueprints or\", start=390.479, duration=3.601), FetchedTranscriptSnippet(text='any techniques that Nvidia makes up or', start=392.08, duration=3.76), FetchedTranscriptSnippet(text='discovers, which means a lot of the', start=394.08, duration=3.52), FetchedTranscriptSnippet(text=\"things that make Nvidia's chips so good\", start=395.84, duration=4.16), FetchedTranscriptSnippet(text='at generic crazy math processing', start=397.6, duration=5.92), FetchedTranscriptSnippet(text='[\\xa0__\\xa0] is stuff that TSMC knows about', start=400.0, duration=6.16), FetchedTranscriptSnippet(text=\"but can't reuse or resell. And all of\", start=403.52, duration=4.239), FetchedTranscriptSnippet(text='the things that have leaked are so', start=406.16, duration=3.44), FetchedTranscriptSnippet(text='heavily patented that Nvidia will sue', start=407.759, duration=3.841), FetchedTranscriptSnippet(text='your [\\xa0__\\xa0] life out of your soul if', start=409.6, duration=3.76), FetchedTranscriptSnippet(text='you try to copy them. And the reason for', start=411.6, duration=4.879), FetchedTranscriptSnippet(text=\"this is relatively simple. Nvidia's GPUs\", start=413.36, duration=7.279), FetchedTranscriptSnippet(text='are really good at generic compute BS,', start=416.479, duration=6.641), FetchedTranscriptSnippet(text='especially all the fancy vector math', start=420.639, duration=5.28), FetchedTranscriptSnippet(text='stuff and matrix transformations and the', start=423.12, duration=4.16), FetchedTranscriptSnippet(text=\"things you'll hear about on other\", start=425.919, duration=2.961), FetchedTranscriptSnippet(text='YouTube channels that go way deeper in', start=427.28, duration=3.6), FetchedTranscriptSnippet(text='the math. The NVIDIA chips were built to', start=428.88, duration=3.2), FetchedTranscriptSnippet(text='handle those types of things because', start=430.88, duration=3.12), FetchedTranscriptSnippet(text='they were built to handle lots of pixels', start=432.08, duration=4.08), FetchedTranscriptSnippet(text='on a screen. If your processor has four', start=434.0, duration=5.199), FetchedTranscriptSnippet(text='cores and you have to process 1920x 1080', start=436.16, duration=4.96), FetchedTranscriptSnippet(text=\"pixels, that's 2 million pixels you have\", start=439.199, duration=4.241), FetchedTranscriptSnippet(text=\"to process every frame. That's 16\", start=441.12, duration=5.04), FetchedTranscriptSnippet(text='milliseconds of time. Imagine processing', start=443.44, duration=6.64), FetchedTranscriptSnippet(text='over 2 million pixels on 4 to 8 cores in', start=446.16, duration=7.28), FetchedTranscriptSnippet(text='16 milliseconds. Good luck. Good luck.', start=450.08, duration=5.92), FetchedTranscriptSnippet(text='This is why GPUs are so powerful. They', start=453.44, duration=4.24), FetchedTranscriptSnippet(text='have thousands of these much smaller,', start=456.0, duration=4.24), FetchedTranscriptSnippet(text='dumber cores effectively that are built', start=457.68, duration=5.12), FetchedTranscriptSnippet(text='to do this large math transformation', start=460.24, duration=4.239), FetchedTranscriptSnippet(text='stuff. and it can handle these types of', start=462.8, duration=3.519), FetchedTranscriptSnippet(text='workloads much more easily, similar to', start=464.479, duration=3.521), FetchedTranscriptSnippet(text='how they handled things like mining', start=466.319, duration=3.44), FetchedTranscriptSnippet(text=\"cryptocurrencies. I'm probably gonna\", start=468.0, duration=3.44), FetchedTranscriptSnippet(text='date myself a bunch here, but when I was', start=469.759, duration=3.041), FetchedTranscriptSnippet(text='in high school, my favorite thing about', start=471.44, duration=3.28), FetchedTranscriptSnippet(text='having a nice GPU is that it was a free', start=472.8, duration=3.6), FetchedTranscriptSnippet(text='source of income because I could use it', start=474.72, duration=4.0), FetchedTranscriptSnippet(text='to mine Bitcoin because Bitcoin mining', start=476.4, duration=4.639), FetchedTranscriptSnippet(text='was a complex enough math problem that a', start=478.72, duration=4.72), FetchedTranscriptSnippet(text='powerful GPU could solve and you would', start=481.039, duration=4.241), FetchedTranscriptSnippet(text='make some money as you powered the', start=483.44, duration=4.479), FetchedTranscriptSnippet(text='network of Bitcoin. It was so powerful', start=485.28, duration=5.039), FetchedTranscriptSnippet(text='and it was so useful that people started', start=487.919, duration=4.481), FetchedTranscriptSnippet(text='looking for ways to optimize the math', start=490.319, duration=4.081), FetchedTranscriptSnippet(text='because the GPU is really good at these', start=492.4, duration=4.079), FetchedTranscriptSnippet(text=\"types of generic problems. But if you're\", start=494.4, duration=4.16), FetchedTranscriptSnippet(text='doing the exact same thing over and over', start=496.479, duration=5.12), FetchedTranscriptSnippet(text='again, the GPU being so generic stops', start=498.56, duration=6.079), FetchedTranscriptSnippet(text='being as beneficial. And this is why AS6', start=501.599, duration=5.361), FetchedTranscriptSnippet(text='started to become popular. And ASIC, as', start=504.639, duration=3.921), FetchedTranscriptSnippet(text='Google summarizes for us here, thank', start=506.96, duration=3.12), FetchedTranscriptSnippet(text='you. Probably ran on an ASIC, funny', start=508.56, duration=3.44), FetchedTranscriptSnippet(text='enough, is an application specific', start=510.08, duration=3.6), FetchedTranscriptSnippet(text='integrated circuit. They were commonly', start=512.0, duration=3.599), FetchedTranscriptSnippet(text='used for Bitcoin specifically because', start=513.68, duration=3.68), FetchedTranscriptSnippet(text='the Bitcoin math could be optimized', start=515.599, duration=4.401), FetchedTranscriptSnippet(text='further if you made a purpose-built chip', start=517.36, duration=5.52), FetchedTranscriptSnippet(text='to just do that one piece of math. And', start=520.0, duration=5.76), FetchedTranscriptSnippet(text='very quickly, AS6 took over in the', start=522.88, duration=4.48), FetchedTranscriptSnippet(text='Bitcoin mining world to the point where', start=525.76, duration=3.68), FetchedTranscriptSnippet(text='if you were using a GPU, you were losing', start=527.36, duration=4.24), FetchedTranscriptSnippet(text='money because your power bill was', start=529.44, duration=4.079), FetchedTranscriptSnippet(text='greater than what you would make back', start=531.6, duration=3.919), FetchedTranscriptSnippet(text='versus an ASIC minor which was so much', start=533.519, duration=4.481), FetchedTranscriptSnippet(text='more optimized that it was more capable', start=535.519, duration=5.921), FetchedTranscriptSnippet(text='of getting more blocks broken in faster', start=538.0, duration=6.16), FetchedTranscriptSnippet(text='times and using less power. This is the', start=541.44, duration=4.48), FetchedTranscriptSnippet(text='thing that we are here to talk about.', start=544.16, duration=4.56), FetchedTranscriptSnippet(text='Not Bitcoin AS6 but the idea of', start=545.92, duration=5.2), FetchedTranscriptSnippet(text='application specific integrations in', start=548.72, duration=5.04), FetchedTranscriptSnippet(text='general on chips. Cerebras is the most', start=551.12, duration=4.88), FetchedTranscriptSnippet(text='prominent company in this space. The', start=553.76, duration=3.92), FetchedTranscriptSnippet(text='space that we are talking about here is', start=556.0, duration=4.32), FetchedTranscriptSnippet(text='accelerator hardware chips that can be', start=557.68, duration=4.56), FetchedTranscriptSnippet(text='given these workloads and actually', start=560.32, duration=4.16), FetchedTranscriptSnippet(text='perform them and generate results. a', start=562.24, duration=4.48), FetchedTranscriptSnippet(text='chip that can traverse this gigantic', start=564.48, duration=4.72), FetchedTranscriptSnippet(text='pile of parameters that are often', start=566.72, duration=4.72), FetchedTranscriptSnippet(text='hundreds of gigs large, which is the', start=569.2, duration=4.72), FetchedTranscriptSnippet(text='model itself, that it can then use and', start=571.44, duration=4.88), FetchedTranscriptSnippet(text='pull in this pile of text that a user', start=573.92, duration=3.919), FetchedTranscriptSnippet(text='generated or is your chat history or', start=576.32, duration=3.44), FetchedTranscriptSnippet(text='whatever, and combine those two things', start=577.839, duration=3.841), FetchedTranscriptSnippet(text='to figure out which token is most likely', start=579.76, duration=3.68), FetchedTranscriptSnippet(text='to be next. By using all of the', start=581.68, duration=3.76), FetchedTranscriptSnippet(text='parameters and its giant map, adding in', start=583.44, duration=3.839), FetchedTranscriptSnippet(text='the math it calculates off of the text', start=585.44, duration=3.92), FetchedTranscriptSnippet(text='you put in to point it towards what', start=587.279, duration=4.321), FetchedTranscriptSnippet(text='parameter is most likely to be next.', start=589.36, duration=4.56), FetchedTranscriptSnippet(text=\"It's this giant web of vectors pointing\", start=591.6, duration=4.72), FetchedTranscriptSnippet(text='to and from each other that is hard math', start=593.92, duration=4.72), FetchedTranscriptSnippet(text='to calculate, but it turns out you can', start=596.32, duration=4.639), FetchedTranscriptSnippet(text='optimize chips to be way better at it.', start=598.64, duration=4.08), FetchedTranscriptSnippet(text='GPUs are better than almost anything', start=600.959, duration=3.201), FetchedTranscriptSnippet(text='else that exists in the traditional', start=602.72, duration=3.2), FetchedTranscriptSnippet(text='world at this. And since a lot of', start=604.16, duration=4.88), FetchedTranscriptSnippet(text='workloads for training tend to need more', start=605.92, duration=5.359), FetchedTranscriptSnippet(text='competence and capability in what you', start=609.04, duration=4.0), FetchedTranscriptSnippet(text='can do, GPUs are still the chip of', start=611.279, duration=3.361), FetchedTranscriptSnippet(text='choice for training. But when you', start=613.04, duration=3.359), FetchedTranscriptSnippet(text=\"actually want to run the model once it's\", start=614.64, duration=4.0), FetchedTranscriptSnippet(text='done being baked, those same chips are', start=616.399, duration=4.481), FetchedTranscriptSnippet(text='nowhere near as efficient as tailor-made', start=618.64, duration=3.84), FetchedTranscriptSnippet(text='solutions. The other interesting thing', start=620.88, duration=3.12), FetchedTranscriptSnippet(text='here is the companies you think of most', start=622.48, duration=3.039), FetchedTranscriptSnippet(text='immediately when you think of AI, you', start=624.0, duration=3.279), FetchedTranscriptSnippet(text='know, the open AIS and the anthropics', start=625.519, duration=3.361), FetchedTranscriptSnippet(text='and the metas of the world, those', start=627.279, duration=3.281), FetchedTranscriptSnippet(text=\"companies don't make their own\", start=628.88, duration=4.0), FetchedTranscriptSnippet(text='accelerator hardware. They are all just', start=630.56, duration=3.68), FetchedTranscriptSnippet(text='using chips. They buy from other', start=632.88, duration=4.079), FetchedTranscriptSnippet(text='companies, mostly from Nvidia. But there', start=634.24, duration=4.24), FetchedTranscriptSnippet(text='are some investments happening in', start=636.959, duration=3.281), FetchedTranscriptSnippet(text='accelerator hardware. most notably', start=638.48, duration=3.28), FetchedTranscriptSnippet(text='Google, which is the only company that', start=640.24, duration=3.039), FetchedTranscriptSnippet(text='covers everything from the apps you use', start=641.76, duration=3.68), FetchedTranscriptSnippet(text='with AI to the models to the place that', start=643.279, duration=3.921), FetchedTranscriptSnippet(text='you host the models to the hardware the', start=645.44, duration=3.839), FetchedTranscriptSnippet(text=\"models run on. Google's one of the only\", start=647.2, duration=3.6), FetchedTranscriptSnippet(text=\"companies that's competing in all of\", start=649.279, duration=3.041), FetchedTranscriptSnippet(text='those spaces and fighting any success', start=650.8, duration=3.599), FetchedTranscriptSnippet(text=\"with it at all. Even Nvidia doesn't\", start=652.32, duration=3.759), FetchedTranscriptSnippet(text='really let you rent GPUs from the cloud.', start=654.399, duration=2.961), FetchedTranscriptSnippet(text='They bought a company that does it. They', start=656.079, duration=3.121), FetchedTranscriptSnippet(text='barely maintain it. If you want to use a', start=657.36, duration=3.919), FetchedTranscriptSnippet(text='bunch of Nvidia GPUs, you better go buy', start=659.2, duration=3.44), FetchedTranscriptSnippet(text='them from Nvidia or find somebody else', start=661.279, duration=3.201), FetchedTranscriptSnippet(text='who already has. So Nvidia has', start=662.64, duration=3.52), FetchedTranscriptSnippet(text='historically been the default option', start=664.48, duration=3.68), FetchedTranscriptSnippet(text='that all these other companies rely on', start=666.16, duration=4.08), FetchedTranscriptSnippet(text=\"when they're trying to do inference\", start=668.16, duration=4.08), FetchedTranscriptSnippet(text='training and everything else. But that', start=670.24, duration=3.839), FetchedTranscriptSnippet(text='is a wedge that other companies noticed', start=672.24, duration=3.839), FetchedTranscriptSnippet(text='existed. Companies like Grock, Cerebrus,', start=674.079, duration=4.641), FetchedTranscriptSnippet(text='and SANA. All three of these companies', start=676.079, duration=4.641), FetchedTranscriptSnippet(text='know that this can be optimized better,', start=678.72, duration=4.239), FetchedTranscriptSnippet(text='especially the actual inference side', start=680.72, duration=3.84), FetchedTranscriptSnippet(text=\"based on what they've seen in the past\", start=682.959, duration=3.921), FetchedTranscriptSnippet(text='with things like, you know, Bitcoin AS6.', start=684.56, duration=4.08), FetchedTranscriptSnippet(text=\"There's obviously opportunity here to\", start=686.88, duration=3.28), FetchedTranscriptSnippet(text='make things that are faster for doing', start=688.64, duration=3.36), FetchedTranscriptSnippet(text='inference. If you want proof of this,', start=690.16, duration=4.0), FetchedTranscriptSnippet(text='look no further than Open Router. If', start=692.0, duration=3.68), FetchedTranscriptSnippet(text=\"you're not familiar, Open Router lets\", start=694.16, duration=3.6), FetchedTranscriptSnippet(text='you route your LLM traffic across', start=695.68, duration=3.599), FetchedTranscriptSnippet(text='different places to make it easier to', start=697.76, duration=3.12), FetchedTranscriptSnippet(text=\"change out what model you're using, what\", start=699.279, duration=3.201), FetchedTranscriptSnippet(text='platform is hosting the model, things', start=700.88, duration=3.12), FetchedTranscriptSnippet(text=\"like that. So, it's really easy to take\", start=702.48, duration=4.4), FetchedTranscriptSnippet(text='an open weight model like GPOSS120B', start=704.0, duration=4.64), FetchedTranscriptSnippet(text=\"and change where you're actually running\", start=706.88, duration=3.76), FetchedTranscriptSnippet(text='it because you just change the string or', start=708.64, duration=3.759), FetchedTranscriptSnippet(text='let them do it for you. Companies like', start=710.64, duration=3.28), FetchedTranscriptSnippet(text='Deep Infra, which are using traditional', start=712.399, duration=3.521), FetchedTranscriptSnippet(text='Nvidia GPUs, can run this model at', start=713.92, duration=4.159), FetchedTranscriptSnippet(text='around 60 tokens per second. on my', start=715.92, duration=4.159), FetchedTranscriptSnippet(text='laptop, on my MacBook, I could run the', start=718.079, duration=4.161), FetchedTranscriptSnippet(text='same model at 80 tokens per second. But', start=720.079, duration=3.521), FetchedTranscriptSnippet(text='if you scroll down to a company like', start=722.24, duration=3.92), FetchedTranscriptSnippet(text='Grock, which again makes their own chips', start=723.6, duration=5.039), FetchedTranscriptSnippet(text='for this purpose, you go from 60 to 80', start=726.16, duration=6.56), FetchedTranscriptSnippet(text='TPS up to 360 tokens per second or with', start=728.639, duration=7.76), FetchedTranscriptSnippet(text='Cerebrris all the way up to 702 TPS.', start=732.72, duration=6.0), FetchedTranscriptSnippet(text=\"That's a 10x difference. That means it's\", start=736.399, duration=5.281), FetchedTranscriptSnippet(text='running the model 10 times faster.', start=738.72, duration=5.119), FetchedTranscriptSnippet(text='Insane. There are models where Cerebras', start=741.68, duration=4.8), FetchedTranscriptSnippet(text='can pull 3,000 TPS if the optimizations', start=743.839, duration=4.56), FetchedTranscriptSnippet(text='are right and the model is built to work', start=746.48, duration=3.359), FetchedTranscriptSnippet(text='well with the architecture of their', start=748.399, duration=3.281), FetchedTranscriptSnippet(text='chips. One of the most common complaints', start=749.839, duration=3.521), FetchedTranscriptSnippet(text='with OpenAI models right now, especially', start=751.68, duration=4.399), FetchedTranscriptSnippet(text='models like GPT 5.2 codecs, is that they', start=753.36, duration=4.24), FetchedTranscriptSnippet(text=\"are really smart, but they're really\", start=756.079, duration=3.601), FetchedTranscriptSnippet(text='slow and just not as pleasant to use as', start=757.6, duration=3.679), FetchedTranscriptSnippet(text='a result. Which is why this partnership', start=759.68, duration=3.12), FetchedTranscriptSnippet(text='is really exciting and why the first', start=761.279, duration=3.36), FetchedTranscriptSnippet(text='thing Sam Alman had to say about it was', start=762.8, duration=4.56), FetchedTranscriptSnippet(text='very fast codecs coming. Yeah, this is a', start=764.639, duration=5.2), FetchedTranscriptSnippet(text='bet to let them make the models way', start=767.36, duration=5.279), FetchedTranscriptSnippet(text='faster and also theoretically speaking,', start=769.839, duration=4.641), FetchedTranscriptSnippet(text='free up some of their NVIDIA GPUs that', start=772.639, duration=3.2), FetchedTranscriptSnippet(text='were being used for this inference. So,', start=774.48, duration=3.12), FetchedTranscriptSnippet(text='they could use those GPUs for training', start=775.839, duration=3.521), FetchedTranscriptSnippet(text=\"instead. Every GPU you're using for\", start=777.6, duration=3.2), FetchedTranscriptSnippet(text=\"training is a GPU you can't use for\", start=779.36, duration=2.88), FetchedTranscriptSnippet(text='inference. So, if they move inference', start=780.8, duration=3.2), FetchedTranscriptSnippet(text='off GPUs, they have more of them', start=782.24, duration=3.44), FetchedTranscriptSnippet(text='available for doing training work. And', start=784.0, duration=3.04), FetchedTranscriptSnippet(text='when you look into a company like', start=785.68, duration=3.04), FetchedTranscriptSnippet(text=\"Cerebras, you see just how hard they're\", start=787.04, duration=3.76), FetchedTranscriptSnippet(text='going to make all of this happen. They', start=788.72, duration=4.239), FetchedTranscriptSnippet(text='make gigantic chips on one hand because', start=790.8, duration=3.839), FetchedTranscriptSnippet(text='they want to put more things on them,', start=792.959, duration=3.601), FetchedTranscriptSnippet(text=\"but also because they don't have access\", start=794.639, duration=3.841), FetchedTranscriptSnippet(text='to the same manufacturing that Nvidia', start=796.56, duration=4.079), FetchedTranscriptSnippet(text='does for TSMC. So, their actual die', start=798.48, duration=4.4), FetchedTranscriptSnippet(text='sizes have to be larger as well. That', start=800.639, duration=4.401), FetchedTranscriptSnippet(text='said, their wafers can do crazy', start=802.88, duration=4.16), FetchedTranscriptSnippet(text=\"inference. It's wild to look at this and\", start=805.04, duration=3.84), FetchedTranscriptSnippet(text='see how gigantic the chips are. The', start=807.04, duration=3.44), FetchedTranscriptSnippet(text='problem with manufacturing chips that', start=808.88, duration=4.24), FetchedTranscriptSnippet(text='are this big is that having all of the', start=810.48, duration=4.96), FetchedTranscriptSnippet(text='pieces you put into it work is likely', start=813.12, duration=4.08), FetchedTranscriptSnippet(text='not going to happen. The bigger the chip', start=815.44, duration=3.519), FetchedTranscriptSnippet(text='is and the more dyes you put on it, the', start=817.2, duration=3.12), FetchedTranscriptSnippet(text='higher chance that some of those are', start=818.959, duration=2.721), FetchedTranscriptSnippet(text='failing, which is one of the big things', start=820.32, duration=3.199), FetchedTranscriptSnippet(text=\"they've had to innovate in a lot. How do\", start=821.68, duration=3.12), FetchedTranscriptSnippet(text='you reduce the failure rates low enough', start=823.519, duration=2.961), FetchedTranscriptSnippet(text='that you can actually make a chip this', start=824.8, duration=3.36), FetchedTranscriptSnippet(text='big without having a bunch of the dies', start=826.48, duration=3.919), FetchedTranscriptSnippet(text='dead on it on arrival? Also, notice how', start=828.16, duration=3.76), FetchedTranscriptSnippet(text=\"little information they're putting on\", start=830.399, duration=4.161), FetchedTranscriptSnippet(text='the page here. That is a choice. These', start=831.92, duration=5.279), FetchedTranscriptSnippet(text='companies are all hiding the absolute', start=834.56, duration=4.959), FetchedTranscriptSnippet(text='[\\xa0__\\xa0] out of everything that they are', start=837.199, duration=5.44), FetchedTranscriptSnippet(text='doing. Cerebras, Grock, Sonova, Nvidia,', start=839.519, duration=5.601), FetchedTranscriptSnippet(text='AMD, Intel, none of these companies are', start=842.639, duration=4.801), FetchedTranscriptSnippet(text='sharing any details about how they make', start=845.12, duration=3.6), FetchedTranscriptSnippet(text='these things. This is the type of', start=847.44, duration=3.04), FetchedTranscriptSnippet(text='information that like you need to sign', start=848.72, duration=4.559), FetchedTranscriptSnippet(text='15 NDAs, promise your firstborn child,', start=850.48, duration=5.68), FetchedTranscriptSnippet(text='and then wear a top tobottom gown that', start=853.279, duration=4.641), FetchedTranscriptSnippet(text='is static proof, and go through a room', start=856.16, duration=3.119), FetchedTranscriptSnippet(text=\"to be sanitized before you're even\", start=857.92, duration=3.44), FetchedTranscriptSnippet(text='allowed inside of the facility. The', start=859.279, duration=3.441), FetchedTranscriptSnippet(text='amount of secrecy and privacy around', start=861.36, duration=2.8), FetchedTranscriptSnippet(text='these things makes Apple look like an', start=862.72, duration=3.28), FetchedTranscriptSnippet(text=\"open- source company. It's kind of nuts,\", start=864.16, duration=3.44), FetchedTranscriptSnippet(text=\"but there's a reason for it. There's a\", start=866.0, duration=3.519), FetchedTranscriptSnippet(text='very expensive reason for it. Nvidia is', start=867.6, duration=5.359), FetchedTranscriptSnippet(text='worth $4.5 trillion. If the secrets that', start=869.519, duration=5.12), FetchedTranscriptSnippet(text='make their chip so good become public', start=872.959, duration=3.761), FetchedTranscriptSnippet(text='information, Nvidia is no longer worth', start=874.639, duration=5.361), FetchedTranscriptSnippet(text='$4.5 trillion. And Nvidia knows this and', start=876.72, duration=4.799), FetchedTranscriptSnippet(text='is scared of this, which is why they', start=880.0, duration=4.079), FetchedTranscriptSnippet(text='spent 20 billion of those 4.5 trillion', start=881.519, duration=4.161), FetchedTranscriptSnippet(text='to do a partnership with one of these', start=884.079, duration=3.841), FetchedTranscriptSnippet(text='chip companies, Grock. Not Grock with a', start=885.68, duration=5.2), FetchedTranscriptSnippet(text='K. Grock with a Q. Grock with a Q is one', start=887.92, duration=4.64), FetchedTranscriptSnippet(text='of the companies building these chips.', start=890.88, duration=4.8), FetchedTranscriptSnippet(text='They refer to their chips as the LPUs.', start=892.56, duration=4.48), FetchedTranscriptSnippet(text='These chips are built for doing', start=895.68, duration=3.2), FetchedTranscriptSnippet(text='inference really, really performantly,', start=897.04, duration=2.799), FetchedTranscriptSnippet(text=\"just like the other ones we're talking\", start=898.88, duration=2.72), FetchedTranscriptSnippet(text='about. No wasted operations, no', start=899.839, duration=3.521), FetchedTranscriptSnippet(text='unpredictable delays, every cycle', start=901.6, duration=3.44), FetchedTranscriptSnippet(text='accounted for. They also integrate the', start=903.36, duration=3.52), FetchedTranscriptSnippet(text='memory on chip because then things end', start=905.04, duration=3.28), FetchedTranscriptSnippet(text='up being way faster and you can squeeze', start=906.88, duration=3.36), FetchedTranscriptSnippet(text='way more RAM on to fit bigger models.', start=908.32, duration=3.12), FetchedTranscriptSnippet(text=\"They're power efficient. They're on\", start=910.24, duration=2.719), FetchedTranscriptSnippet(text='these gigantic racks that they put', start=911.44, duration=3.759), FetchedTranscriptSnippet(text='wherever they can in the world. They', start=912.959, duration=4.081), FetchedTranscriptSnippet(text='also often have to build their own SDKs', start=915.199, duration=3.921), FetchedTranscriptSnippet(text=\"because remember you don't get access to\", start=917.04, duration=3.919), FetchedTranscriptSnippet(text='cool things like CUDA anymore, the', start=919.12, duration=4.079), FetchedTranscriptSnippet(text='standard for building GPU optimized work', start=920.959, duration=5.041), FetchedTranscriptSnippet(text=\"when you have a chip that's not a GPU.\", start=923.199, duration=4.64), FetchedTranscriptSnippet(text='So that not only are these companies', start=926.0, duration=3.6), FetchedTranscriptSnippet(text=\"rethinking the actual chips that we're\", start=927.839, duration=3.201), FetchedTranscriptSnippet(text='running everything on, they also have to', start=929.6, duration=4.0), FetchedTranscriptSnippet(text='rethink the SDKs in the software that', start=931.04, duration=4.4), FetchedTranscriptSnippet(text=\"we're building on top of them. And often\", start=933.6, duration=3.12), FetchedTranscriptSnippet(text='this is a back and forth where a company', start=935.44, duration=3.28), FetchedTranscriptSnippet(text='like Grock has to deeply analyze how a', start=936.72, duration=4.16), FetchedTranscriptSnippet(text='model like Llama works, what parts of', start=938.72, duration=4.0), FetchedTranscriptSnippet(text=\"the GPU it's hitting, and then take\", start=940.88, duration=4.079), FetchedTranscriptSnippet(text='those things and optimize them to Helen', start=942.72, duration=4.08), FetchedTranscriptSnippet(text='back to squeeze into a custom chip. And', start=944.959, duration=3.601), FetchedTranscriptSnippet(text='that back and forth is crazy. Sometimes', start=946.8, duration=3.52), FetchedTranscriptSnippet(text=\"a new model drops and it doesn't fit\", start=948.56, duration=3.279), FetchedTranscriptSnippet(text='well on a Grock chip. And now they have', start=950.32, duration=2.959), FetchedTranscriptSnippet(text='to go back to the drawing board and make', start=951.839, duration=3.68), FetchedTranscriptSnippet(text='modifications both to the model and to', start=953.279, duration=4.24), FetchedTranscriptSnippet(text='the chip to try and make them mesh', start=955.519, duration=3.361), FetchedTranscriptSnippet(text=\"better. And since everything's still\", start=957.519, duration=2.801), FetchedTranscriptSnippet(text=\"trained on Nvidia, everything's still\", start=958.88, duration=3.84), FetchedTranscriptSnippet(text='largely built to be run on Nvidia. So', start=960.32, duration=4.48), FetchedTranscriptSnippet(text='yeah, it turns out when you make a chip', start=962.72, duration=3.76), FetchedTranscriptSnippet(text='for a specific purpose, you can', start=964.8, duration=3.36), FetchedTranscriptSnippet(text='outperform chips that are made for more', start=966.48, duration=4.159), FetchedTranscriptSnippet(text=\"generic work. And the only way Nvidia's\", start=968.16, duration=4.799), FetchedTranscriptSnippet(text='current architecture would keep them as', start=970.639, duration=4.401), FetchedTranscriptSnippet(text='number one is if it turns out by some', start=972.959, duration=4.721), FetchedTranscriptSnippet(text='weird divine intervention that GPU', start=975.04, duration=5.2), FetchedTranscriptSnippet(text='architecture is just magically the exact', start=977.68, duration=4.079), FetchedTranscriptSnippet(text='architecture that makes the most sense', start=980.24, duration=3.76), FetchedTranscriptSnippet(text='for doing AI work. In order to beat', start=981.759, duration=4.08), FetchedTranscriptSnippet(text='Nvidia, you have to replace all of the', start=984.0, duration=3.759), FetchedTranscriptSnippet(text='things that make Nvidia great. You have', start=985.839, duration=3.201), FetchedTranscriptSnippet(text='to have all of the things that they do', start=987.759, duration=3.041), FetchedTranscriptSnippet(text='in a generic way accessible in other', start=989.04, duration=3.2), FetchedTranscriptSnippet(text='places. You have to handle the fact that', start=990.8, duration=4.0), FetchedTranscriptSnippet(text=\"everything's built around CUDA and crazy\", start=992.24, duration=4.159), FetchedTranscriptSnippet(text=\"tools around it just aren't going to\", start=994.8, duration=3.2), FetchedTranscriptSnippet(text='work on these other things yet. You have', start=996.399, duration=3.601), FetchedTranscriptSnippet(text='to be prepared to fight on all of those', start=998.0, duration=3.519), FetchedTranscriptSnippet(text=\"levels. But there's a lot of companies\", start=1000.0, duration=3.04), FetchedTranscriptSnippet(text='that are prepared for that fight and are', start=1001.519, duration=3.44), FetchedTranscriptSnippet(text=\"pushing hard. But it's important to know\", start=1003.04, duration=4.56), FetchedTranscriptSnippet(text='how long that takes as well. When TSMC', start=1004.959, duration=4.641), FetchedTranscriptSnippet(text='wants to spin up new manufacturing, that', start=1007.6, duration=3.44), FetchedTranscriptSnippet(text=\"doesn't happen in months. That doesn't\", start=1009.6, duration=3.599), FetchedTranscriptSnippet(text='happen in a year. It takes five plus', start=1011.04, duration=4.56), FetchedTranscriptSnippet(text='years for TSMC to say, \"Okay, we have', start=1013.199, duration=3.921), FetchedTranscriptSnippet(text='this process. We want to implement it.', start=1015.6, duration=2.88), FetchedTranscriptSnippet(text=\"We're going to build a new factory for\", start=1017.12, duration=4.719), FetchedTranscriptSnippet(text='it.\" 5 to 10 years. That\\'s also why the', start=1018.48, duration=4.88), FetchedTranscriptSnippet(text='chip shortages are happening now because', start=1021.839, duration=3.521), FetchedTranscriptSnippet(text='the demand went up. And it takes 5 to 10', start=1023.36, duration=4.24), FetchedTranscriptSnippet(text='years for the manufacturing to catch up.', start=1025.36, duration=3.439), FetchedTranscriptSnippet(text=\"That's also why we're starting to see\", start=1027.6, duration=3.199), FetchedTranscriptSnippet(text='these companies like Grock and Cerebras', start=1028.799, duration=3.601), FetchedTranscriptSnippet(text='finally really getting competitive', start=1030.799, duration=3.361), FetchedTranscriptSnippet(text=\"because it's been about 5 to 10 years\", start=1032.4, duration=3.919), FetchedTranscriptSnippet(text='since they started. But in the end,', start=1034.16, duration=4.399), FetchedTranscriptSnippet(text='margins always win. And the margins', start=1036.319, duration=4.88), FetchedTranscriptSnippet(text='Nvidia has right now are far too high', start=1038.559, duration=4.961), FetchedTranscriptSnippet(text=\"when their chips aren't as optimized as\", start=1041.199, duration=3.76), FetchedTranscriptSnippet(text=\"they could be. Right now, we're putting\", start=1043.52, duration=2.559), FetchedTranscriptSnippet(text='a lot of money into training and', start=1044.959, duration=3.681), FetchedTranscriptSnippet(text='inference, but over time, if the AI', start=1046.079, duration=4.641), FetchedTranscriptSnippet(text=\"bubble continues to grow, we'll have\", start=1048.64, duration=4.0), FetchedTranscriptSnippet(text='way, way more money and time going into', start=1050.72, duration=4.079), FetchedTranscriptSnippet(text='the inference side, and Nvidia selling', start=1052.64, duration=3.68), FetchedTranscriptSnippet(text='chips for inference will stop making', start=1054.799, duration=3.601), FetchedTranscriptSnippet(text='sense very quickly with basic economics', start=1056.32, duration=5.52), FetchedTranscriptSnippet(text='of scale. But until then, I suspect, and', start=1058.4, duration=5.279), FetchedTranscriptSnippet(text='again, this is not financial advice, I', start=1061.84, duration=3.44), FetchedTranscriptSnippet(text='would expect Nvidia to stay pretty close', start=1063.679, duration=4.0), FetchedTranscriptSnippet(text='to the top for a while as the market', start=1065.28, duration=5.6), FetchedTranscriptSnippet(text='slowly realizes that TSMC is the company', start=1067.679, duration=5.041), FetchedTranscriptSnippet(text='actually producing the value. And more', start=1070.88, duration=4.0), FetchedTranscriptSnippet(text='importantly, the novelty that makes', start=1072.72, duration=4.48), FetchedTranscriptSnippet(text='Nvidia so high up here is something that', start=1074.88, duration=3.76), FetchedTranscriptSnippet(text=\"they aren't necessarily the best\", start=1077.2, duration=2.96), FetchedTranscriptSnippet(text=\"solution for. I think I've said all I\", start=1078.64, duration=3.279), FetchedTranscriptSnippet(text=\"have to here. It's always fun to rage at\", start=1080.16, duration=4.08), FetchedTranscriptSnippet(text='Nvidia as a lifetime gamer that has a', start=1081.919, duration=3.841), FetchedTranscriptSnippet(text='lot of opinions about the company, but', start=1084.24, duration=2.88), FetchedTranscriptSnippet(text=\"in the end, I'm just excited to see\", start=1085.76, duration=2.72), FetchedTranscriptSnippet(text='competition happening and for inference', start=1087.12, duration=3.2), FetchedTranscriptSnippet(text='to get faster. I want these models to', start=1088.48, duration=3.92), FetchedTranscriptSnippet(text='run as fast as we can possibly have them', start=1090.32, duration=3.52), FetchedTranscriptSnippet(text='because that makes them easier to use', start=1092.4, duration=2.8), FetchedTranscriptSnippet(text='and more powerful in our day-to-day', start=1093.84, duration=3.28), FetchedTranscriptSnippet(text=\"work. I'm excited to run things like\", start=1095.2, duration=4.16), FetchedTranscriptSnippet(text='codecs on 3,000 tokens per second', start=1097.12, duration=4.0), FetchedTranscriptSnippet(text='instead of the measly 30 to 40 that we', start=1099.36, duration=3.04), FetchedTranscriptSnippet(text='get today. Let me know what you guys', start=1101.12, duration=5.36), FetchedTranscriptSnippet(text='think. And until next time, peace nerds.', start=1102.4, duration=4.08)], video_id='J8lxHyQmcaI', language='English (auto-generated)', language_code='en', is_generated=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetched_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchedTranscriptSnippet(text='valuable company in the world? I mean,', start=1.36, duration=3.919)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetched_transcript[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81455d-556a-441b-8912-78492d3c8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "    TRANSCRIPT_API_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TRANSCRIPT_API_AVAILABLE = False\n",
    "\n",
    "\n",
    "class TranscriptFetcher:\n",
    "    \"\"\"Fetches and cleans YouTube video transcripts.\"\"\"\n",
    "\n",
    "    # Common filler words/sounds to remove\n",
    "    FILLER_WORDS = {\n",
    "        \"um\",\n",
    "        \"uh\",\n",
    "        \"like\",\n",
    "        \"you know\",\n",
    "        \"basically\",\n",
    "        \"literally\",\n",
    "        \"actually\",\n",
    "        \"honestly\",\n",
    "        \"right\",\n",
    "        \"so\",\n",
    "        \"yeah\",\n",
    "        \"okay\",\n",
    "        \"alright\",\n",
    "        \"well\",\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize TranscriptFetcher.\"\"\"\n",
    "        if not TRANSCRIPT_API_AVAILABLE:\n",
    "            raise RuntimeError(\n",
    "                \"youtube-transcript-api not installed. Install with: pip install youtube-transcript-api\"\n",
    "            )\n",
    "\n",
    "    def fetch_transcript(self, video_id: str, languages: list = None) -> str | None:\n",
    "        \"\"\"\n",
    "        Fetch transcript for a YouTube video.\n",
    "\n",
    "        Args:\n",
    "            video_id: YouTube video ID\n",
    "            languages: List of language codes to try (e.g., ['en', 'es'])\n",
    "\n",
    "        Returns:\n",
    "            Transcript text or None if not available\n",
    "        \"\"\"\n",
    "        if not TRANSCRIPT_API_AVAILABLE:\n",
    "            raise RuntimeError(\"youtube-transcript-api not installed\")\n",
    "\n",
    "        if languages is None:\n",
    "            languages = [\"en\"]\n",
    "\n",
    "        try:\n",
    "            \n",
    "            # transcript = YouTubeTranscriptApi.fetch(video_id, languages=languages)\n",
    "            ytt_api = YouTubeTranscriptApi()\n",
    "            transcript = ytt_api.fetch(video_id, languages=languages)\n",
    "            # Merge transcript entries into continuous text\n",
    "            text = \" \".join([entry[\"text\"] for entry in transcript])\n",
    "            return text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch transcript for video {video_id}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def clean_transcript(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Clean raw transcript text.\n",
    "\n",
    "        Operations:\n",
    "        - Remove timestamps and brackets\n",
    "        - Normalize spaces\n",
    "        - Remove filler words at start of sentences\n",
    "        - Remove repeated punctuation\n",
    "\n",
    "        Args:\n",
    "            text: Raw transcript text\n",
    "\n",
    "        Returns:\n",
    "            Cleaned text\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "\n",
    "        # Remove bracketed content (like [Music], [Applause])\n",
    "        text = re.sub(r\"\\[.*?\\]\", \"\", text)\n",
    "\n",
    "        # Remove multiple spaces\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "        # Remove repeated punctuation\n",
    "        text = re.sub(r\"\\.{2,}\", \".\", text)\n",
    "        text = re.sub(r\"!{2,}\", \"!\", text)\n",
    "        text = re.sub(r\"\\?{2,}\", \"?\", text)\n",
    "\n",
    "        # Clean up filler words at the beginning of sentences\n",
    "        text = self._remove_filler_words(text)\n",
    "\n",
    "        # Normalize spacing around punctuation\n",
    "        text = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", text)\n",
    "        text = re.sub(r\"([.,!?;:])\\s*([a-zA-Z])\", r\"\\1 \\2\", text)\n",
    "\n",
    "        return text.strip()\n",
    "\n",
    "    def _remove_filler_words(self, text: str) -> str:\n",
    "        \"\"\"Remove filler words at the beginning of sentences.\"\"\"\n",
    "        sentences = text.split(\". \")\n",
    "        cleaned_sentences = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            words = sentence.split()\n",
    "            # Remove leading filler words\n",
    "            while words and words[0].lower().rstrip(\",\") in self.FILLER_WORDS:\n",
    "                words.pop(0)\n",
    "\n",
    "            if words:\n",
    "                cleaned_sentences.append(\" \".join(words))\n",
    "\n",
    "        return \". \".join(cleaned_sentences)\n",
    "\n",
    "    def fetch_and_clean(\n",
    "        self, video_id: str, title: str, link: str, languages: list = None\n",
    "    ) -> Dict[str, Any] | None:\n",
    "        \"\"\"\n",
    "        Fetch and clean transcript in one call.\n",
    "\n",
    "        Args:\n",
    "            video_id: YouTube video ID\n",
    "            title: Video title\n",
    "            link: Video link\n",
    "            languages: Language preferences\n",
    "\n",
    "        Returns:\n",
    "            Dict with video_id, title, clean_text, link or None\n",
    "        \"\"\"\n",
    "        raw_text = self.fetch_transcript(video_id, languages)\n",
    "\n",
    "        if raw_text is None:\n",
    "            return None\n",
    "\n",
    "        clean_text = self.clean_transcript(raw_text)\n",
    "\n",
    "        return {\n",
    "            \"video_id\": video_id,\n",
    "            \"title\": title,\n",
    "            \"clean_text\": clean_text,\n",
    "            \"link\": link,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076e28f-254c-4e4a-8f02-afce1b15c9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not fetch transcript for video J8lxHyQmcaI: 'FetchedTranscriptSnippet' object is not subscriptable\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Akaash\\Desktop\\D_Drive\\Project\\AI_NewsLetter\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3709: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"Quick manual test for fetching a transcript.\"\"\"\n",
    "    video_id = \"J8lxHyQmcaI\"  # sample video id\n",
    "    fetcher = TranscriptFetcher()\n",
    "    transcript = fetcher.fetch_transcript(video_id)\n",
    "    if transcript:\n",
    "        print(json.dumps({\"video_id\": video_id, \"excerpt\": transcript[:500]}, indent=2))\n",
    "    else:\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba52d6a-4767-46e3-a7f3-dc5eb770aaa8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'languages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m ytt_api = YouTubeTranscriptApi()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m transcript = ytt_api.fetch(video_id, languages=\u001b[43mlanguages\u001b[49m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Merge transcript entries into continuous text\u001b[39;00m\n\u001b[32m      4\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join([entry[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m transcript])\n",
      "\u001b[31mNameError\u001b[39m: name 'languages' is not defined"
     ]
    }
   ],
   "source": [
    "ytt_api = YouTubeTranscriptApi()\n",
    "transcript = ytt_api.fetch(video_id, languages=languages)\n",
    "# Merge transcript entries into continuous text\n",
    "text = \" \".join([entry[\"text\"] for entry in transcript])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77546aa0-a85c-4cd4-bce9-479114a2165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa15dca3-d1a1-428f-9b63-2887a5507a99",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'FetchedTranscriptSnippet' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m transcript = ytt_api.fetch(video_id, languages=languages)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Merge transcript entries into continuous text\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m transcript])\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "\u001b[31mTypeError\u001b[39m: 'FetchedTranscriptSnippet' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "ytt_api = YouTubeTranscriptApi()\n",
    "transcript = ytt_api.fetch(video_id, languages=languages)\n",
    "# Merge transcript entries into continuous text\n",
    "text = \" \".join([entry[\"text\"] for entry in transcript])\n",
    "return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ab7ef-528e-41ea-846d-8dd55cc37669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchedTranscript(snippets=[FetchedTranscriptSnippet(text='Did you know that Nvidia is the most', start=0.0, duration=3.36), FetchedTranscriptSnippet(text='valuable company in the world? I mean,', start=1.36, duration=3.919), FetchedTranscriptSnippet(text='it makes sense, right? All of these huge', start=3.36, duration=3.6), FetchedTranscriptSnippet(text='AI companies are relying on them fully', start=5.279, duration=3.761), FetchedTranscriptSnippet(text='in order to do the AI stuff that we all', start=6.96, duration=3.84), FetchedTranscriptSnippet(text=\"expect them to do. That's why Nvidia's\", start=9.04, duration=4.24), FetchedTranscriptSnippet(text='value is comparable to that of silver.', start=10.8, duration=4.64), FetchedTranscriptSnippet(text='Yes, all of the silver in the world is', start=13.28, duration=4.32), FetchedTranscriptSnippet(text='comparable to the value of Nvidia, just', start=15.44, duration=4.32), FetchedTranscriptSnippet(text='one company that makes chips for gamers.', start=17.6, duration=4.0), FetchedTranscriptSnippet(text='And now those same chips turn out to be', start=19.76, duration=3.519), FetchedTranscriptSnippet(text='really good for AI stuff, which is why', start=21.6, duration=3.28), FetchedTranscriptSnippet(text='everybody is using them. So, does', start=23.279, duration=3.84), FetchedTranscriptSnippet(text=\"Anthropic, oh, Anthropic's moving to\", start=24.88, duration=4.08), FetchedTranscriptSnippet(text=\"Google's TPUs? Well, that's fine.\", start=27.119, duration=3.041), FetchedTranscriptSnippet(text=\"There's plenty of other companies that\", start=28.96, duration=3.439), FetchedTranscriptSnippet(text=\"aren't doing that like OpenAI. Oh,\", start=30.16, duration=4.64), FetchedTranscriptSnippet(text='OpenAI is partnering with Cerebrris, the', start=32.399, duration=4.0), FetchedTranscriptSnippet(text=\"chip company. Well, at least there's\", start=34.8, duration=4.96), FetchedTranscriptSnippet(text=\"Meta, right? Oh, Google's working to\", start=36.399, duration=5.361), FetchedTranscriptSnippet(text=\"erode Nvidia's software advantage with\", start=39.76, duration=4.0), FetchedTranscriptSnippet(text=\"Meta's help. Google's going to be giving\", start=41.76, duration=5.44), FetchedTranscriptSnippet(text='TPUs to Meta. Huh. Very interesting. In', start=43.76, duration=5.76), FetchedTranscriptSnippet(text='fact, things have gotten so crazy that', start=47.2, duration=4.4), FetchedTranscriptSnippet(text='even Nvidia is investing in alternatives', start=49.52, duration=4.08), FetchedTranscriptSnippet(text='to Nvidia, like Grock, who they just', start=51.6, duration=3.599), FetchedTranscriptSnippet(text=\"paid some crazy number. It's currently\", start=53.6, duration=4.4), FetchedTranscriptSnippet(text='estimated around $20 billion to license', start=55.199, duration=4.561), FetchedTranscriptSnippet(text=\"Grock's technology and pull its founder\", start=58.0, duration=3.76), FetchedTranscriptSnippet(text='and some other people over to bring what', start=59.76, duration=4.08), FetchedTranscriptSnippet(text='Grock does to Nvidia because it turns', start=61.76, duration=5.12), FetchedTranscriptSnippet(text='out GPUs might not actually be the best', start=63.84, duration=5.279), FetchedTranscriptSnippet(text=\"solution for AI going forward. It's\", start=66.88, duration=3.919), FetchedTranscriptSnippet(text='crazy to think that the literal most', start=69.119, duration=3.841), FetchedTranscriptSnippet(text='valuable company in the world might be', start=70.799, duration=4.081), FetchedTranscriptSnippet(text='selling a type of chip that stops being', start=72.96, duration=3.92), FetchedTranscriptSnippet(text='relevant in the next few years, if not', start=74.88, duration=4.559), FetchedTranscriptSnippet(text='even few months. And I have a lot to say', start=76.88, duration=3.919), FetchedTranscriptSnippet(text=\"about it. But you know what's likely\", start=79.439, duration=3.761), FetchedTranscriptSnippet(text=\"going to stay valuable? Today's sponsor.\", start=80.799, duration=4.081), FetchedTranscriptSnippet(text=\"One of the biggest hiccups I've seen for\", start=83.2, duration=3.84), FetchedTranscriptSnippet(text='big companies adopting AI tools is the', start=84.88, duration=4.16), FetchedTranscriptSnippet(text='change in the mindset and flow. A lot of', start=87.04, duration=3.68), FetchedTranscriptSnippet(text=\"their stuff just isn't built for moving\", start=89.04, duration=4.16), FetchedTranscriptSnippet(text='this fast. In particular, their CI. How', start=90.72, duration=4.56), FetchedTranscriptSnippet(text='great is it to file 10 PRs a day if', start=93.2, duration=4.239), FetchedTranscriptSnippet(text='those PRs take 40 minutes each to build?', start=95.28, duration=3.6), FetchedTranscriptSnippet(text='Be a lot better if they took under a', start=97.439, duration=3.281), FetchedTranscriptSnippet(text='minute, right? That sounds impossible', start=98.88, duration=3.199), FetchedTranscriptSnippet(text=\"though. Unless you're using today's\", start=100.72, duration=3.28), FetchedTranscriptSnippet(text='sponsor, Depot. These guys will make', start=102.079, duration=4.961), FetchedTranscriptSnippet(text='your builds absurdly fast. Post Hog got', start=104.0, duration=6.24), FetchedTranscriptSnippet(text='30 times faster. Their builds went from', start=107.04, duration=6.719), FetchedTranscriptSnippet(text=\"138 minutes down to 4 and a half. That's\", start=110.24, duration=6.879), FetchedTranscriptSnippet(text='hilariously faster. Even the worst case', start=113.759, duration=6.561), FetchedTranscriptSnippet(text='with Zed still saw a 1.4x increase. Most', start=117.119, duration=5.441), FetchedTranscriptSnippet(text='saw closer to 3 to 20x though with', start=120.32, duration=5.52), FetchedTranscriptSnippet(text='Mastadon hitting 19x from 46 minutes to', start=122.56, duration=5.6), FetchedTranscriptSnippet(text='2 1/2. I like how Post Hog put this', start=125.84, duration=4.88), FetchedTranscriptSnippet(text='best. Around here, we say Post Hog ships', start=128.16, duration=4.56), FetchedTranscriptSnippet(text=\"weirdly fast. And you can't say Post Hog\", start=130.72, duration=3.599), FetchedTranscriptSnippet(text=\"ships weirdly fast if you're waiting for\", start=132.72, duration=4.0), FetchedTranscriptSnippet(text='an hour and 45 minutes for it to ship. I', start=134.319, duration=3.761), FetchedTranscriptSnippet(text='personally experienced this when we were', start=136.72, duration=3.12), FetchedTranscriptSnippet(text='trying to ship changes on T3 chat for', start=138.08, duration=3.68), FetchedTranscriptSnippet(text='our wrapped feature and Post Hog was', start=139.84, duration=3.52), FetchedTranscriptSnippet(text='shipping stuff for us. They got things', start=141.76, duration=3.68), FetchedTranscriptSnippet(text='shipped during a holiday week in', start=143.36, duration=4.0), FetchedTranscriptSnippet(text='literally 10 minutes because their', start=145.44, duration=4.08), FetchedTranscriptSnippet(text='builds finished almost instantly because', start=147.36, duration=4.32), FetchedTranscriptSnippet(text='they moved depot. Depot unblocked', start=149.52, duration=4.4), FetchedTranscriptSnippet(text=\"features for me. That's something I\", start=151.68, duration=4.559), FetchedTranscriptSnippet(text=\"can't say about very many sponsors. It's\", start=153.92, duration=4.16), FetchedTranscriptSnippet(text='time to stop wasting time. Fix your', start=156.239, duration=4.241), FetchedTranscriptSnippet(text='builds at soyv.link/depo.', start=158.08, duration=4.64), FetchedTranscriptSnippet(text=\"So, let's talk a bit about why Nvidia's\", start=160.48, duration=4.479), FetchedTranscriptSnippet(text='kind of doomed. In order to understand', start=162.72, duration=4.0), FetchedTranscriptSnippet(text='this, we need to first understand how we', start=164.959, duration=3.92), FetchedTranscriptSnippet(text='got here in the first place. Why is it', start=166.72, duration=3.76), FetchedTranscriptSnippet(text='that the company that made graphics', start=168.879, duration=4.72), FetchedTranscriptSnippet(text='cards for our gaming PCs suddenly became', start=170.48, duration=5.68), FetchedTranscriptSnippet(text='the most valuable company in the world?', start=173.599, duration=4.321), FetchedTranscriptSnippet(text='I could go way too deep on the weird', start=176.16, duration=4.32), FetchedTranscriptSnippet(text='history of Nvidia as a hardware partner', start=177.92, duration=5.2), FetchedTranscriptSnippet(text='from how they [\\xa0__\\xa0] over Apple, so many', start=180.48, duration=4.16), FetchedTranscriptSnippet(text=\"other things. I just I'm a nerd about\", start=183.12, duration=3.36), FetchedTranscriptSnippet(text='this. I know way too much. I have been', start=184.64, duration=4.0), FetchedTranscriptSnippet(text='an Nvidia hater for the better part of', start=186.48, duration=4.479), FetchedTranscriptSnippet(text='like 15 or so years now because they', start=188.64, duration=4.879), FetchedTranscriptSnippet(text='made my life as a PC builder way harder.', start=190.959, duration=4.241), FetchedTranscriptSnippet(text=\"They made Apple's lives way harder. They\", start=193.519, duration=3.761), FetchedTranscriptSnippet(text=\"Nvidia's just been a really bad player\", start=195.2, duration=5.119), FetchedTranscriptSnippet(text='in the market for a long, long time. But', start=197.28, duration=5.52), FetchedTranscriptSnippet(text='Nvidia did have one thing, the best', start=200.319, duration=5.601), FetchedTranscriptSnippet(text='GPUs. It turns out making GPUs is hard.', start=202.8, duration=4.96), FetchedTranscriptSnippet(text=\"That's why so many companies have been\", start=205.92, duration=4.399), FetchedTranscriptSnippet(text='struggling to get into it themselves.', start=207.76, duration=4.399), FetchedTranscriptSnippet(text='Intel started their own GPU division a', start=210.319, duration=3.761), FetchedTranscriptSnippet(text='few years ago in order to try and catch', start=212.159, duration=4.16), FetchedTranscriptSnippet(text='up with Nvidia and AMD and they have', start=214.08, duration=4.879), FetchedTranscriptSnippet(text='struggled immensely. AMD tried and', start=216.319, duration=4.401), FetchedTranscriptSnippet(text='failed as well and instead chose to buy', start=218.959, duration=3.441), FetchedTranscriptSnippet(text='out ATI which was a company that was', start=220.72, duration=3.28), FetchedTranscriptSnippet(text='competing pretty close with Nvidia at', start=222.4, duration=3.52), FetchedTranscriptSnippet(text='the time, the time being like 20 years', start=224.0, duration=4.4), FetchedTranscriptSnippet(text='ago and since then has been folded fully', start=225.92, duration=4.56), FetchedTranscriptSnippet(text='into AMD as their graphics division. And', start=228.4, duration=3.68), FetchedTranscriptSnippet(text='those graphics chips are the ones being', start=230.48, duration=3.759), FetchedTranscriptSnippet(text='used in most home consoles today. Things', start=232.08, duration=3.92), FetchedTranscriptSnippet(text='like the Xbox and the PlayStation', start=234.239, duration=3.92), FetchedTranscriptSnippet(text='because both Sony and Microsoft have', start=236.0, duration=3.76), FetchedTranscriptSnippet(text='moved as far away from Nvidia as', start=238.159, duration=3.44), FetchedTranscriptSnippet(text=\"possible because they've had so many\", start=239.76, duration=3.679), FetchedTranscriptSnippet(text='problems with them. And funny enough,', start=241.599, duration=3.92), FetchedTranscriptSnippet(text='the only one still betting on Nvidia for', start=243.439, duration=4.0), FetchedTranscriptSnippet(text='consoles is Nintendo because they inked', start=245.519, duration=4.08), FetchedTranscriptSnippet(text='some crazy private deal in order to use', start=247.439, duration=4.561), FetchedTranscriptSnippet(text=\"all of Nvidia's failed ARM chips that\", start=249.599, duration=4.081), FetchedTranscriptSnippet(text='they were trying to sell for tablets,', start=252.0, duration=3.12), FetchedTranscriptSnippet(text='trying to move those to the Switch in', start=253.68, duration=2.799), FetchedTranscriptSnippet(text='hopes of finding a market for it. And', start=255.12, duration=2.799), FetchedTranscriptSnippet(text='that went better than anyone would have', start=256.479, duration=3.921), FetchedTranscriptSnippet(text=\"expected. So Nvidia's only console\", start=257.919, duration=5.041), FetchedTranscriptSnippet(text='sales, only gaming sales right now are', start=260.4, duration=4.32), FetchedTranscriptSnippet(text='to Nintendo of all companies. But for', start=262.96, duration=3.92), FetchedTranscriptSnippet(text='the most part, Nvidia has pissed off all', start=264.72, duration=4.16), FetchedTranscriptSnippet(text='of their partners over the last 20 years', start=266.88, duration=3.68), FetchedTranscriptSnippet(text='to the point where very few of them', start=268.88, duration=4.16), FetchedTranscriptSnippet(text='still choose to rely heavily on Nvidia', start=270.56, duration=4.8), FetchedTranscriptSnippet(text='in the hardware sales and distribution', start=273.04, duration=3.84), FetchedTranscriptSnippet(text='space. And the reason they get away with', start=275.36, duration=3.92), FetchedTranscriptSnippet(text='it is again making GPUs is really,', start=276.88, duration=4.56), FetchedTranscriptSnippet(text=\"really hard. It's so hard that Nvidia\", start=279.28, duration=3.76), FetchedTranscriptSnippet(text=\"doesn't even do it themselves. So what\", start=281.44, duration=3.6), FetchedTranscriptSnippet(text='the hell makes Nvidia so valuable then', start=283.04, duration=4.24), FetchedTranscriptSnippet(text=\"if they're not making the GPUs? company\", start=285.04, duration=3.92), FetchedTranscriptSnippet(text=\"that's actually making the chips and the\", start=287.28, duration=3.359), FetchedTranscriptSnippet(text='dyes and the silicon that goes into', start=288.96, duration=4.56), FetchedTranscriptSnippet(text=\"Nvidia's GPUs is a company named TSMC,\", start=290.639, duration=4.881), FetchedTranscriptSnippet(text=\"Taiwan's semiconductor manufacturing\", start=293.52, duration=3.92), FetchedTranscriptSnippet(text='company. These guys manufacture the', start=295.52, duration=4.0), FetchedTranscriptSnippet(text='silicon for all of the best chips in the', start=297.44, duration=3.84), FetchedTranscriptSnippet(text='world. There are other companies that', start=299.52, duration=3.84), FetchedTranscriptSnippet(text='make chips, but none of them make chips', start=301.28, duration=5.52), FetchedTranscriptSnippet(text='as small, refined, and powerful as TSMC.', start=303.36, duration=5.119), FetchedTranscriptSnippet(text=\"That's why Apple relies on them heavily\", start=306.8, duration=3.92), FetchedTranscriptSnippet(text='for all of their chips. The reason the M', start=308.479, duration=4.56), FetchedTranscriptSnippet(text='series Maxs and the iPhones and iPads in', start=310.72, duration=4.0), FetchedTranscriptSnippet(text='general are so performant is because', start=313.039, duration=4.081), FetchedTranscriptSnippet(text='Apple made a bet on TSMC early as their', start=314.72, duration=4.24), FetchedTranscriptSnippet(text='silicon manufacturing partner. And more', start=317.12, duration=3.44), FetchedTranscriptSnippet(text='and more companies have had to move over', start=318.96, duration=3.44), FetchedTranscriptSnippet(text='as well, including crazy enough', start=320.56, duration=3.359), FetchedTranscriptSnippet(text='companies like Intel that historically', start=322.4, duration=3.76), FetchedTranscriptSnippet(text='have owned their own manufacturing. TSMC', start=323.919, duration=4.72), FetchedTranscriptSnippet(text='is in my opinion the company that is', start=326.16, duration=5.28), FetchedTranscriptSnippet(text='actually most valuable by far across all', start=328.639, duration=5.28), FetchedTranscriptSnippet(text='of this because without TSMC the', start=331.44, duration=4.4), FetchedTranscriptSnippet(text='performance that we expect from Nvidia,', start=333.919, duration=4.0), FetchedTranscriptSnippet(text='from AMD, from Intel, from Apple, from', start=335.84, duration=4.079), FetchedTranscriptSnippet(text='all these things is no longer possible.', start=337.919, duration=3.921), FetchedTranscriptSnippet(text='This company is what the next world war', start=339.919, duration=3.921), FetchedTranscriptSnippet(text='will probably start around. As crazy as', start=341.84, duration=4.4), FetchedTranscriptSnippet(text='that sounds, whoever controls TSMC kind', start=343.84, duration=4.32), FetchedTranscriptSnippet(text='of controls how powerful chips are for', start=346.24, duration=4.239), FetchedTranscriptSnippet(text='the rest of the world. But TSMC is just', start=348.16, duration=4.16), FetchedTranscriptSnippet(text='taking a blueprint and constructing it.', start=350.479, duration=3.361), FetchedTranscriptSnippet(text='Those blueprints have to come from', start=352.32, duration=3.2), FetchedTranscriptSnippet(text='companies. Those specs, those plans,', start=353.84, duration=3.28), FetchedTranscriptSnippet(text='those tolerances, those expectations,', start=355.52, duration=4.16), FetchedTranscriptSnippet(text='the SDKs and platforms around them, the', start=357.12, duration=3.919), FetchedTranscriptSnippet(text=\"thing that you're actually shipping to a\", start=359.68, duration=3.6), FetchedTranscriptSnippet(text=\"user. TSMC isn't shipping a chip to a\", start=361.039, duration=4.481), FetchedTranscriptSnippet(text='user. TSMC is taking in a blueprint,', start=363.28, duration=4.16), FetchedTranscriptSnippet(text='printing it onto an impossibly small', start=365.52, duration=3.76), FetchedTranscriptSnippet(text='die, and then sending that to a company', start=367.44, duration=3.52), FetchedTranscriptSnippet(text='like Apple or Nvidia to do what they', start=369.28, duration=3.919), FetchedTranscriptSnippet(text='want to with. And Nvidia has really,', start=370.96, duration=5.12), FetchedTranscriptSnippet(text='really good architecture for doing GPUs', start=373.199, duration=4.481), FetchedTranscriptSnippet(text='through processes being developed by', start=376.08, duration=4.88), FetchedTranscriptSnippet(text='TSMC. Nvidia comes up with crazy ways to', start=377.68, duration=5.519), FetchedTranscriptSnippet(text='do compute with silicon that they then', start=380.96, duration=4.4), FetchedTranscriptSnippet(text='forward to TSMC as a plan that gets', start=383.199, duration=3.44), FetchedTranscriptSnippet(text='manufactured and then given back to', start=385.36, duration=2.88), FetchedTranscriptSnippet(text='Nvidia. And part of the agreement is', start=386.639, duration=3.84), FetchedTranscriptSnippet(text=\"that TSMC can't keep those blueprints,\", start=388.24, duration=3.84), FetchedTranscriptSnippet(text=\"can't reuse or sell those blueprints or\", start=390.479, duration=3.601), FetchedTranscriptSnippet(text='any techniques that Nvidia makes up or', start=392.08, duration=3.76), FetchedTranscriptSnippet(text='discovers, which means a lot of the', start=394.08, duration=3.52), FetchedTranscriptSnippet(text=\"things that make Nvidia's chips so good\", start=395.84, duration=4.16), FetchedTranscriptSnippet(text='at generic crazy math processing', start=397.6, duration=5.92), FetchedTranscriptSnippet(text='[\\xa0__\\xa0] is stuff that TSMC knows about', start=400.0, duration=6.16), FetchedTranscriptSnippet(text=\"but can't reuse or resell. And all of\", start=403.52, duration=4.239), FetchedTranscriptSnippet(text='the things that have leaked are so', start=406.16, duration=3.44), FetchedTranscriptSnippet(text='heavily patented that Nvidia will sue', start=407.759, duration=3.841), FetchedTranscriptSnippet(text='your [\\xa0__\\xa0] life out of your soul if', start=409.6, duration=3.76), FetchedTranscriptSnippet(text='you try to copy them. And the reason for', start=411.6, duration=4.879), FetchedTranscriptSnippet(text=\"this is relatively simple. Nvidia's GPUs\", start=413.36, duration=7.279), FetchedTranscriptSnippet(text='are really good at generic compute BS,', start=416.479, duration=6.641), FetchedTranscriptSnippet(text='especially all the fancy vector math', start=420.639, duration=5.28), FetchedTranscriptSnippet(text='stuff and matrix transformations and the', start=423.12, duration=4.16), FetchedTranscriptSnippet(text=\"things you'll hear about on other\", start=425.919, duration=2.961), FetchedTranscriptSnippet(text='YouTube channels that go way deeper in', start=427.28, duration=3.6), FetchedTranscriptSnippet(text='the math. The NVIDIA chips were built to', start=428.88, duration=3.2), FetchedTranscriptSnippet(text='handle those types of things because', start=430.88, duration=3.12), FetchedTranscriptSnippet(text='they were built to handle lots of pixels', start=432.08, duration=4.08), FetchedTranscriptSnippet(text='on a screen. If your processor has four', start=434.0, duration=5.199), FetchedTranscriptSnippet(text='cores and you have to process 1920x 1080', start=436.16, duration=4.96), FetchedTranscriptSnippet(text=\"pixels, that's 2 million pixels you have\", start=439.199, duration=4.241), FetchedTranscriptSnippet(text=\"to process every frame. That's 16\", start=441.12, duration=5.04), FetchedTranscriptSnippet(text='milliseconds of time. Imagine processing', start=443.44, duration=6.64), FetchedTranscriptSnippet(text='over 2 million pixels on 4 to 8 cores in', start=446.16, duration=7.28), FetchedTranscriptSnippet(text='16 milliseconds. Good luck. Good luck.', start=450.08, duration=5.92), FetchedTranscriptSnippet(text='This is why GPUs are so powerful. They', start=453.44, duration=4.24), FetchedTranscriptSnippet(text='have thousands of these much smaller,', start=456.0, duration=4.24), FetchedTranscriptSnippet(text='dumber cores effectively that are built', start=457.68, duration=5.12), FetchedTranscriptSnippet(text='to do this large math transformation', start=460.24, duration=4.239), FetchedTranscriptSnippet(text='stuff. and it can handle these types of', start=462.8, duration=3.519), FetchedTranscriptSnippet(text='workloads much more easily, similar to', start=464.479, duration=3.521), FetchedTranscriptSnippet(text='how they handled things like mining', start=466.319, duration=3.44), FetchedTranscriptSnippet(text=\"cryptocurrencies. I'm probably gonna\", start=468.0, duration=3.44), FetchedTranscriptSnippet(text='date myself a bunch here, but when I was', start=469.759, duration=3.041), FetchedTranscriptSnippet(text='in high school, my favorite thing about', start=471.44, duration=3.28), FetchedTranscriptSnippet(text='having a nice GPU is that it was a free', start=472.8, duration=3.6), FetchedTranscriptSnippet(text='source of income because I could use it', start=474.72, duration=4.0), FetchedTranscriptSnippet(text='to mine Bitcoin because Bitcoin mining', start=476.4, duration=4.639), FetchedTranscriptSnippet(text='was a complex enough math problem that a', start=478.72, duration=4.72), FetchedTranscriptSnippet(text='powerful GPU could solve and you would', start=481.039, duration=4.241), FetchedTranscriptSnippet(text='make some money as you powered the', start=483.44, duration=4.479), FetchedTranscriptSnippet(text='network of Bitcoin. It was so powerful', start=485.28, duration=5.039), FetchedTranscriptSnippet(text='and it was so useful that people started', start=487.919, duration=4.481), FetchedTranscriptSnippet(text='looking for ways to optimize the math', start=490.319, duration=4.081), FetchedTranscriptSnippet(text='because the GPU is really good at these', start=492.4, duration=4.079), FetchedTranscriptSnippet(text=\"types of generic problems. But if you're\", start=494.4, duration=4.16), FetchedTranscriptSnippet(text='doing the exact same thing over and over', start=496.479, duration=5.12), FetchedTranscriptSnippet(text='again, the GPU being so generic stops', start=498.56, duration=6.079), FetchedTranscriptSnippet(text='being as beneficial. And this is why AS6', start=501.599, duration=5.361), FetchedTranscriptSnippet(text='started to become popular. And ASIC, as', start=504.639, duration=3.921), FetchedTranscriptSnippet(text='Google summarizes for us here, thank', start=506.96, duration=3.12), FetchedTranscriptSnippet(text='you. Probably ran on an ASIC, funny', start=508.56, duration=3.44), FetchedTranscriptSnippet(text='enough, is an application specific', start=510.08, duration=3.6), FetchedTranscriptSnippet(text='integrated circuit. They were commonly', start=512.0, duration=3.599), FetchedTranscriptSnippet(text='used for Bitcoin specifically because', start=513.68, duration=3.68), FetchedTranscriptSnippet(text='the Bitcoin math could be optimized', start=515.599, duration=4.401), FetchedTranscriptSnippet(text='further if you made a purpose-built chip', start=517.36, duration=5.52), FetchedTranscriptSnippet(text='to just do that one piece of math. And', start=520.0, duration=5.76), FetchedTranscriptSnippet(text='very quickly, AS6 took over in the', start=522.88, duration=4.48), FetchedTranscriptSnippet(text='Bitcoin mining world to the point where', start=525.76, duration=3.68), FetchedTranscriptSnippet(text='if you were using a GPU, you were losing', start=527.36, duration=4.24), FetchedTranscriptSnippet(text='money because your power bill was', start=529.44, duration=4.079), FetchedTranscriptSnippet(text='greater than what you would make back', start=531.6, duration=3.919), FetchedTranscriptSnippet(text='versus an ASIC minor which was so much', start=533.519, duration=4.481), FetchedTranscriptSnippet(text='more optimized that it was more capable', start=535.519, duration=5.921), FetchedTranscriptSnippet(text='of getting more blocks broken in faster', start=538.0, duration=6.16), FetchedTranscriptSnippet(text='times and using less power. This is the', start=541.44, duration=4.48), FetchedTranscriptSnippet(text='thing that we are here to talk about.', start=544.16, duration=4.56), FetchedTranscriptSnippet(text='Not Bitcoin AS6 but the idea of', start=545.92, duration=5.2), FetchedTranscriptSnippet(text='application specific integrations in', start=548.72, duration=5.04), FetchedTranscriptSnippet(text='general on chips. Cerebras is the most', start=551.12, duration=4.88), FetchedTranscriptSnippet(text='prominent company in this space. The', start=553.76, duration=3.92), FetchedTranscriptSnippet(text='space that we are talking about here is', start=556.0, duration=4.32), FetchedTranscriptSnippet(text='accelerator hardware chips that can be', start=557.68, duration=4.56), FetchedTranscriptSnippet(text='given these workloads and actually', start=560.32, duration=4.16), FetchedTranscriptSnippet(text='perform them and generate results. a', start=562.24, duration=4.48), FetchedTranscriptSnippet(text='chip that can traverse this gigantic', start=564.48, duration=4.72), FetchedTranscriptSnippet(text='pile of parameters that are often', start=566.72, duration=4.72), FetchedTranscriptSnippet(text='hundreds of gigs large, which is the', start=569.2, duration=4.72), FetchedTranscriptSnippet(text='model itself, that it can then use and', start=571.44, duration=4.88), FetchedTranscriptSnippet(text='pull in this pile of text that a user', start=573.92, duration=3.919), FetchedTranscriptSnippet(text='generated or is your chat history or', start=576.32, duration=3.44), FetchedTranscriptSnippet(text='whatever, and combine those two things', start=577.839, duration=3.841), FetchedTranscriptSnippet(text='to figure out which token is most likely', start=579.76, duration=3.68), FetchedTranscriptSnippet(text='to be next. By using all of the', start=581.68, duration=3.76), FetchedTranscriptSnippet(text='parameters and its giant map, adding in', start=583.44, duration=3.839), FetchedTranscriptSnippet(text='the math it calculates off of the text', start=585.44, duration=3.92), FetchedTranscriptSnippet(text='you put in to point it towards what', start=587.279, duration=4.321), FetchedTranscriptSnippet(text='parameter is most likely to be next.', start=589.36, duration=4.56), FetchedTranscriptSnippet(text=\"It's this giant web of vectors pointing\", start=591.6, duration=4.72), FetchedTranscriptSnippet(text='to and from each other that is hard math', start=593.92, duration=4.72), FetchedTranscriptSnippet(text='to calculate, but it turns out you can', start=596.32, duration=4.639), FetchedTranscriptSnippet(text='optimize chips to be way better at it.', start=598.64, duration=4.08), FetchedTranscriptSnippet(text='GPUs are better than almost anything', start=600.959, duration=3.201), FetchedTranscriptSnippet(text='else that exists in the traditional', start=602.72, duration=3.2), FetchedTranscriptSnippet(text='world at this. And since a lot of', start=604.16, duration=4.88), FetchedTranscriptSnippet(text='workloads for training tend to need more', start=605.92, duration=5.359), FetchedTranscriptSnippet(text='competence and capability in what you', start=609.04, duration=4.0), FetchedTranscriptSnippet(text='can do, GPUs are still the chip of', start=611.279, duration=3.361), FetchedTranscriptSnippet(text='choice for training. But when you', start=613.04, duration=3.359), FetchedTranscriptSnippet(text=\"actually want to run the model once it's\", start=614.64, duration=4.0), FetchedTranscriptSnippet(text='done being baked, those same chips are', start=616.399, duration=4.481), FetchedTranscriptSnippet(text='nowhere near as efficient as tailor-made', start=618.64, duration=3.84), FetchedTranscriptSnippet(text='solutions. The other interesting thing', start=620.88, duration=3.12), FetchedTranscriptSnippet(text='here is the companies you think of most', start=622.48, duration=3.039), FetchedTranscriptSnippet(text='immediately when you think of AI, you', start=624.0, duration=3.279), FetchedTranscriptSnippet(text='know, the open AIS and the anthropics', start=625.519, duration=3.361), FetchedTranscriptSnippet(text='and the metas of the world, those', start=627.279, duration=3.281), FetchedTranscriptSnippet(text=\"companies don't make their own\", start=628.88, duration=4.0), FetchedTranscriptSnippet(text='accelerator hardware. They are all just', start=630.56, duration=3.68), FetchedTranscriptSnippet(text='using chips. They buy from other', start=632.88, duration=4.079), FetchedTranscriptSnippet(text='companies, mostly from Nvidia. But there', start=634.24, duration=4.24), FetchedTranscriptSnippet(text='are some investments happening in', start=636.959, duration=3.281), FetchedTranscriptSnippet(text='accelerator hardware. most notably', start=638.48, duration=3.28), FetchedTranscriptSnippet(text='Google, which is the only company that', start=640.24, duration=3.039), FetchedTranscriptSnippet(text='covers everything from the apps you use', start=641.76, duration=3.68), FetchedTranscriptSnippet(text='with AI to the models to the place that', start=643.279, duration=3.921), FetchedTranscriptSnippet(text='you host the models to the hardware the', start=645.44, duration=3.839), FetchedTranscriptSnippet(text=\"models run on. Google's one of the only\", start=647.2, duration=3.6), FetchedTranscriptSnippet(text=\"companies that's competing in all of\", start=649.279, duration=3.041), FetchedTranscriptSnippet(text='those spaces and fighting any success', start=650.8, duration=3.599), FetchedTranscriptSnippet(text=\"with it at all. Even Nvidia doesn't\", start=652.32, duration=3.759), FetchedTranscriptSnippet(text='really let you rent GPUs from the cloud.', start=654.399, duration=2.961), FetchedTranscriptSnippet(text='They bought a company that does it. They', start=656.079, duration=3.121), FetchedTranscriptSnippet(text='barely maintain it. If you want to use a', start=657.36, duration=3.919), FetchedTranscriptSnippet(text='bunch of Nvidia GPUs, you better go buy', start=659.2, duration=3.44), FetchedTranscriptSnippet(text='them from Nvidia or find somebody else', start=661.279, duration=3.201), FetchedTranscriptSnippet(text='who already has. So Nvidia has', start=662.64, duration=3.52), FetchedTranscriptSnippet(text='historically been the default option', start=664.48, duration=3.68), FetchedTranscriptSnippet(text='that all these other companies rely on', start=666.16, duration=4.08), FetchedTranscriptSnippet(text=\"when they're trying to do inference\", start=668.16, duration=4.08), FetchedTranscriptSnippet(text='training and everything else. But that', start=670.24, duration=3.839), FetchedTranscriptSnippet(text='is a wedge that other companies noticed', start=672.24, duration=3.839), FetchedTranscriptSnippet(text='existed. Companies like Grock, Cerebrus,', start=674.079, duration=4.641), FetchedTranscriptSnippet(text='and SANA. All three of these companies', start=676.079, duration=4.641), FetchedTranscriptSnippet(text='know that this can be optimized better,', start=678.72, duration=4.239), FetchedTranscriptSnippet(text='especially the actual inference side', start=680.72, duration=3.84), FetchedTranscriptSnippet(text=\"based on what they've seen in the past\", start=682.959, duration=3.921), FetchedTranscriptSnippet(text='with things like, you know, Bitcoin AS6.', start=684.56, duration=4.08), FetchedTranscriptSnippet(text=\"There's obviously opportunity here to\", start=686.88, duration=3.28), FetchedTranscriptSnippet(text='make things that are faster for doing', start=688.64, duration=3.36), FetchedTranscriptSnippet(text='inference. If you want proof of this,', start=690.16, duration=4.0), FetchedTranscriptSnippet(text='look no further than Open Router. If', start=692.0, duration=3.68), FetchedTranscriptSnippet(text=\"you're not familiar, Open Router lets\", start=694.16, duration=3.6), FetchedTranscriptSnippet(text='you route your LLM traffic across', start=695.68, duration=3.599), FetchedTranscriptSnippet(text='different places to make it easier to', start=697.76, duration=3.12), FetchedTranscriptSnippet(text=\"change out what model you're using, what\", start=699.279, duration=3.201), FetchedTranscriptSnippet(text='platform is hosting the model, things', start=700.88, duration=3.12), FetchedTranscriptSnippet(text=\"like that. So, it's really easy to take\", start=702.48, duration=4.4), FetchedTranscriptSnippet(text='an open weight model like GPOSS120B', start=704.0, duration=4.64), FetchedTranscriptSnippet(text=\"and change where you're actually running\", start=706.88, duration=3.76), FetchedTranscriptSnippet(text='it because you just change the string or', start=708.64, duration=3.759), FetchedTranscriptSnippet(text='let them do it for you. Companies like', start=710.64, duration=3.28), FetchedTranscriptSnippet(text='Deep Infra, which are using traditional', start=712.399, duration=3.521), FetchedTranscriptSnippet(text='Nvidia GPUs, can run this model at', start=713.92, duration=4.159), FetchedTranscriptSnippet(text='around 60 tokens per second. on my', start=715.92, duration=4.159), FetchedTranscriptSnippet(text='laptop, on my MacBook, I could run the', start=718.079, duration=4.161), FetchedTranscriptSnippet(text='same model at 80 tokens per second. But', start=720.079, duration=3.521), FetchedTranscriptSnippet(text='if you scroll down to a company like', start=722.24, duration=3.92), FetchedTranscriptSnippet(text='Grock, which again makes their own chips', start=723.6, duration=5.039), FetchedTranscriptSnippet(text='for this purpose, you go from 60 to 80', start=726.16, duration=6.56), FetchedTranscriptSnippet(text='TPS up to 360 tokens per second or with', start=728.639, duration=7.76), FetchedTranscriptSnippet(text='Cerebrris all the way up to 702 TPS.', start=732.72, duration=6.0), FetchedTranscriptSnippet(text=\"That's a 10x difference. That means it's\", start=736.399, duration=5.281), FetchedTranscriptSnippet(text='running the model 10 times faster.', start=738.72, duration=5.119), FetchedTranscriptSnippet(text='Insane. There are models where Cerebras', start=741.68, duration=4.8), FetchedTranscriptSnippet(text='can pull 3,000 TPS if the optimizations', start=743.839, duration=4.56), FetchedTranscriptSnippet(text='are right and the model is built to work', start=746.48, duration=3.359), FetchedTranscriptSnippet(text='well with the architecture of their', start=748.399, duration=3.281), FetchedTranscriptSnippet(text='chips. One of the most common complaints', start=749.839, duration=3.521), FetchedTranscriptSnippet(text='with OpenAI models right now, especially', start=751.68, duration=4.399), FetchedTranscriptSnippet(text='models like GPT 5.2 codecs, is that they', start=753.36, duration=4.24), FetchedTranscriptSnippet(text=\"are really smart, but they're really\", start=756.079, duration=3.601), FetchedTranscriptSnippet(text='slow and just not as pleasant to use as', start=757.6, duration=3.679), FetchedTranscriptSnippet(text='a result. Which is why this partnership', start=759.68, duration=3.12), FetchedTranscriptSnippet(text='is really exciting and why the first', start=761.279, duration=3.36), FetchedTranscriptSnippet(text='thing Sam Alman had to say about it was', start=762.8, duration=4.56), FetchedTranscriptSnippet(text='very fast codecs coming. Yeah, this is a', start=764.639, duration=5.2), FetchedTranscriptSnippet(text='bet to let them make the models way', start=767.36, duration=5.279), FetchedTranscriptSnippet(text='faster and also theoretically speaking,', start=769.839, duration=4.641), FetchedTranscriptSnippet(text='free up some of their NVIDIA GPUs that', start=772.639, duration=3.2), FetchedTranscriptSnippet(text='were being used for this inference. So,', start=774.48, duration=3.12), FetchedTranscriptSnippet(text='they could use those GPUs for training', start=775.839, duration=3.521), FetchedTranscriptSnippet(text=\"instead. Every GPU you're using for\", start=777.6, duration=3.2), FetchedTranscriptSnippet(text=\"training is a GPU you can't use for\", start=779.36, duration=2.88), FetchedTranscriptSnippet(text='inference. So, if they move inference', start=780.8, duration=3.2), FetchedTranscriptSnippet(text='off GPUs, they have more of them', start=782.24, duration=3.44), FetchedTranscriptSnippet(text='available for doing training work. And', start=784.0, duration=3.04), FetchedTranscriptSnippet(text='when you look into a company like', start=785.68, duration=3.04), FetchedTranscriptSnippet(text=\"Cerebras, you see just how hard they're\", start=787.04, duration=3.76), FetchedTranscriptSnippet(text='going to make all of this happen. They', start=788.72, duration=4.239), FetchedTranscriptSnippet(text='make gigantic chips on one hand because', start=790.8, duration=3.839), FetchedTranscriptSnippet(text='they want to put more things on them,', start=792.959, duration=3.601), FetchedTranscriptSnippet(text=\"but also because they don't have access\", start=794.639, duration=3.841), FetchedTranscriptSnippet(text='to the same manufacturing that Nvidia', start=796.56, duration=4.079), FetchedTranscriptSnippet(text='does for TSMC. So, their actual die', start=798.48, duration=4.4), FetchedTranscriptSnippet(text='sizes have to be larger as well. That', start=800.639, duration=4.401), FetchedTranscriptSnippet(text='said, their wafers can do crazy', start=802.88, duration=4.16), FetchedTranscriptSnippet(text=\"inference. It's wild to look at this and\", start=805.04, duration=3.84), FetchedTranscriptSnippet(text='see how gigantic the chips are. The', start=807.04, duration=3.44), FetchedTranscriptSnippet(text='problem with manufacturing chips that', start=808.88, duration=4.24), FetchedTranscriptSnippet(text='are this big is that having all of the', start=810.48, duration=4.96), FetchedTranscriptSnippet(text='pieces you put into it work is likely', start=813.12, duration=4.08), FetchedTranscriptSnippet(text='not going to happen. The bigger the chip', start=815.44, duration=3.519), FetchedTranscriptSnippet(text='is and the more dyes you put on it, the', start=817.2, duration=3.12), FetchedTranscriptSnippet(text='higher chance that some of those are', start=818.959, duration=2.721), FetchedTranscriptSnippet(text='failing, which is one of the big things', start=820.32, duration=3.199), FetchedTranscriptSnippet(text=\"they've had to innovate in a lot. How do\", start=821.68, duration=3.12), FetchedTranscriptSnippet(text='you reduce the failure rates low enough', start=823.519, duration=2.961), FetchedTranscriptSnippet(text='that you can actually make a chip this', start=824.8, duration=3.36), FetchedTranscriptSnippet(text='big without having a bunch of the dies', start=826.48, duration=3.919), FetchedTranscriptSnippet(text='dead on it on arrival? Also, notice how', start=828.16, duration=3.76), FetchedTranscriptSnippet(text=\"little information they're putting on\", start=830.399, duration=4.161), FetchedTranscriptSnippet(text='the page here. That is a choice. These', start=831.92, duration=5.279), FetchedTranscriptSnippet(text='companies are all hiding the absolute', start=834.56, duration=4.959), FetchedTranscriptSnippet(text='[\\xa0__\\xa0] out of everything that they are', start=837.199, duration=5.44), FetchedTranscriptSnippet(text='doing. Cerebras, Grock, Sonova, Nvidia,', start=839.519, duration=5.601), FetchedTranscriptSnippet(text='AMD, Intel, none of these companies are', start=842.639, duration=4.801), FetchedTranscriptSnippet(text='sharing any details about how they make', start=845.12, duration=3.6), FetchedTranscriptSnippet(text='these things. This is the type of', start=847.44, duration=3.04), FetchedTranscriptSnippet(text='information that like you need to sign', start=848.72, duration=4.559), FetchedTranscriptSnippet(text='15 NDAs, promise your firstborn child,', start=850.48, duration=5.68), FetchedTranscriptSnippet(text='and then wear a top tobottom gown that', start=853.279, duration=4.641), FetchedTranscriptSnippet(text='is static proof, and go through a room', start=856.16, duration=3.119), FetchedTranscriptSnippet(text=\"to be sanitized before you're even\", start=857.92, duration=3.44), FetchedTranscriptSnippet(text='allowed inside of the facility. The', start=859.279, duration=3.441), FetchedTranscriptSnippet(text='amount of secrecy and privacy around', start=861.36, duration=2.8), FetchedTranscriptSnippet(text='these things makes Apple look like an', start=862.72, duration=3.28), FetchedTranscriptSnippet(text=\"open- source company. It's kind of nuts,\", start=864.16, duration=3.44), FetchedTranscriptSnippet(text=\"but there's a reason for it. There's a\", start=866.0, duration=3.519), FetchedTranscriptSnippet(text='very expensive reason for it. Nvidia is', start=867.6, duration=5.359), FetchedTranscriptSnippet(text='worth $4.5 trillion. If the secrets that', start=869.519, duration=5.12), FetchedTranscriptSnippet(text='make their chip so good become public', start=872.959, duration=3.761), FetchedTranscriptSnippet(text='information, Nvidia is no longer worth', start=874.639, duration=5.361), FetchedTranscriptSnippet(text='$4.5 trillion. And Nvidia knows this and', start=876.72, duration=4.799), FetchedTranscriptSnippet(text='is scared of this, which is why they', start=880.0, duration=4.079), FetchedTranscriptSnippet(text='spent 20 billion of those 4.5 trillion', start=881.519, duration=4.161), FetchedTranscriptSnippet(text='to do a partnership with one of these', start=884.079, duration=3.841), FetchedTranscriptSnippet(text='chip companies, Grock. Not Grock with a', start=885.68, duration=5.2), FetchedTranscriptSnippet(text='K. Grock with a Q. Grock with a Q is one', start=887.92, duration=4.64), FetchedTranscriptSnippet(text='of the companies building these chips.', start=890.88, duration=4.8), FetchedTranscriptSnippet(text='They refer to their chips as the LPUs.', start=892.56, duration=4.48), FetchedTranscriptSnippet(text='These chips are built for doing', start=895.68, duration=3.2), FetchedTranscriptSnippet(text='inference really, really performantly,', start=897.04, duration=2.799), FetchedTranscriptSnippet(text=\"just like the other ones we're talking\", start=898.88, duration=2.72), FetchedTranscriptSnippet(text='about. No wasted operations, no', start=899.839, duration=3.521), FetchedTranscriptSnippet(text='unpredictable delays, every cycle', start=901.6, duration=3.44), FetchedTranscriptSnippet(text='accounted for. They also integrate the', start=903.36, duration=3.52), FetchedTranscriptSnippet(text='memory on chip because then things end', start=905.04, duration=3.28), FetchedTranscriptSnippet(text='up being way faster and you can squeeze', start=906.88, duration=3.36), FetchedTranscriptSnippet(text='way more RAM on to fit bigger models.', start=908.32, duration=3.12), FetchedTranscriptSnippet(text=\"They're power efficient. They're on\", start=910.24, duration=2.719), FetchedTranscriptSnippet(text='these gigantic racks that they put', start=911.44, duration=3.759), FetchedTranscriptSnippet(text='wherever they can in the world. They', start=912.959, duration=4.081), FetchedTranscriptSnippet(text='also often have to build their own SDKs', start=915.199, duration=3.921), FetchedTranscriptSnippet(text=\"because remember you don't get access to\", start=917.04, duration=3.919), FetchedTranscriptSnippet(text='cool things like CUDA anymore, the', start=919.12, duration=4.079), FetchedTranscriptSnippet(text='standard for building GPU optimized work', start=920.959, duration=5.041), FetchedTranscriptSnippet(text=\"when you have a chip that's not a GPU.\", start=923.199, duration=4.64), FetchedTranscriptSnippet(text='So that not only are these companies', start=926.0, duration=3.6), FetchedTranscriptSnippet(text=\"rethinking the actual chips that we're\", start=927.839, duration=3.201), FetchedTranscriptSnippet(text='running everything on, they also have to', start=929.6, duration=4.0), FetchedTranscriptSnippet(text='rethink the SDKs in the software that', start=931.04, duration=4.4), FetchedTranscriptSnippet(text=\"we're building on top of them. And often\", start=933.6, duration=3.12), FetchedTranscriptSnippet(text='this is a back and forth where a company', start=935.44, duration=3.28), FetchedTranscriptSnippet(text='like Grock has to deeply analyze how a', start=936.72, duration=4.16), FetchedTranscriptSnippet(text='model like Llama works, what parts of', start=938.72, duration=4.0), FetchedTranscriptSnippet(text=\"the GPU it's hitting, and then take\", start=940.88, duration=4.079), FetchedTranscriptSnippet(text='those things and optimize them to Helen', start=942.72, duration=4.08), FetchedTranscriptSnippet(text='back to squeeze into a custom chip. And', start=944.959, duration=3.601), FetchedTranscriptSnippet(text='that back and forth is crazy. Sometimes', start=946.8, duration=3.52), FetchedTranscriptSnippet(text=\"a new model drops and it doesn't fit\", start=948.56, duration=3.279), FetchedTranscriptSnippet(text='well on a Grock chip. And now they have', start=950.32, duration=2.959), FetchedTranscriptSnippet(text='to go back to the drawing board and make', start=951.839, duration=3.68), FetchedTranscriptSnippet(text='modifications both to the model and to', start=953.279, duration=4.24), FetchedTranscriptSnippet(text='the chip to try and make them mesh', start=955.519, duration=3.361), FetchedTranscriptSnippet(text=\"better. And since everything's still\", start=957.519, duration=2.801), FetchedTranscriptSnippet(text=\"trained on Nvidia, everything's still\", start=958.88, duration=3.84), FetchedTranscriptSnippet(text='largely built to be run on Nvidia. So', start=960.32, duration=4.48), FetchedTranscriptSnippet(text='yeah, it turns out when you make a chip', start=962.72, duration=3.76), FetchedTranscriptSnippet(text='for a specific purpose, you can', start=964.8, duration=3.36), FetchedTranscriptSnippet(text='outperform chips that are made for more', start=966.48, duration=4.159), FetchedTranscriptSnippet(text=\"generic work. And the only way Nvidia's\", start=968.16, duration=4.799), FetchedTranscriptSnippet(text='current architecture would keep them as', start=970.639, duration=4.401), FetchedTranscriptSnippet(text='number one is if it turns out by some', start=972.959, duration=4.721), FetchedTranscriptSnippet(text='weird divine intervention that GPU', start=975.04, duration=5.2), FetchedTranscriptSnippet(text='architecture is just magically the exact', start=977.68, duration=4.079), FetchedTranscriptSnippet(text='architecture that makes the most sense', start=980.24, duration=3.76), FetchedTranscriptSnippet(text='for doing AI work. In order to beat', start=981.759, duration=4.08), FetchedTranscriptSnippet(text='Nvidia, you have to replace all of the', start=984.0, duration=3.759), FetchedTranscriptSnippet(text='things that make Nvidia great. You have', start=985.839, duration=3.201), FetchedTranscriptSnippet(text='to have all of the things that they do', start=987.759, duration=3.041), FetchedTranscriptSnippet(text='in a generic way accessible in other', start=989.04, duration=3.2), FetchedTranscriptSnippet(text='places. You have to handle the fact that', start=990.8, duration=4.0), FetchedTranscriptSnippet(text=\"everything's built around CUDA and crazy\", start=992.24, duration=4.159), FetchedTranscriptSnippet(text=\"tools around it just aren't going to\", start=994.8, duration=3.2), FetchedTranscriptSnippet(text='work on these other things yet. You have', start=996.399, duration=3.601), FetchedTranscriptSnippet(text='to be prepared to fight on all of those', start=998.0, duration=3.519), FetchedTranscriptSnippet(text=\"levels. But there's a lot of companies\", start=1000.0, duration=3.04), FetchedTranscriptSnippet(text='that are prepared for that fight and are', start=1001.519, duration=3.44), FetchedTranscriptSnippet(text=\"pushing hard. But it's important to know\", start=1003.04, duration=4.56), FetchedTranscriptSnippet(text='how long that takes as well. When TSMC', start=1004.959, duration=4.641), FetchedTranscriptSnippet(text='wants to spin up new manufacturing, that', start=1007.6, duration=3.44), FetchedTranscriptSnippet(text=\"doesn't happen in months. That doesn't\", start=1009.6, duration=3.599), FetchedTranscriptSnippet(text='happen in a year. It takes five plus', start=1011.04, duration=4.56), FetchedTranscriptSnippet(text='years for TSMC to say, \"Okay, we have', start=1013.199, duration=3.921), FetchedTranscriptSnippet(text='this process. We want to implement it.', start=1015.6, duration=2.88), FetchedTranscriptSnippet(text=\"We're going to build a new factory for\", start=1017.12, duration=4.719), FetchedTranscriptSnippet(text='it.\" 5 to 10 years. That\\'s also why the', start=1018.48, duration=4.88), FetchedTranscriptSnippet(text='chip shortages are happening now because', start=1021.839, duration=3.521), FetchedTranscriptSnippet(text='the demand went up. And it takes 5 to 10', start=1023.36, duration=4.24), FetchedTranscriptSnippet(text='years for the manufacturing to catch up.', start=1025.36, duration=3.439), FetchedTranscriptSnippet(text=\"That's also why we're starting to see\", start=1027.6, duration=3.199), FetchedTranscriptSnippet(text='these companies like Grock and Cerebras', start=1028.799, duration=3.601), FetchedTranscriptSnippet(text='finally really getting competitive', start=1030.799, duration=3.361), FetchedTranscriptSnippet(text=\"because it's been about 5 to 10 years\", start=1032.4, duration=3.919), FetchedTranscriptSnippet(text='since they started. But in the end,', start=1034.16, duration=4.399), FetchedTranscriptSnippet(text='margins always win. And the margins', start=1036.319, duration=4.88), FetchedTranscriptSnippet(text='Nvidia has right now are far too high', start=1038.559, duration=4.961), FetchedTranscriptSnippet(text=\"when their chips aren't as optimized as\", start=1041.199, duration=3.76), FetchedTranscriptSnippet(text=\"they could be. Right now, we're putting\", start=1043.52, duration=2.559), FetchedTranscriptSnippet(text='a lot of money into training and', start=1044.959, duration=3.681), FetchedTranscriptSnippet(text='inference, but over time, if the AI', start=1046.079, duration=4.641), FetchedTranscriptSnippet(text=\"bubble continues to grow, we'll have\", start=1048.64, duration=4.0), FetchedTranscriptSnippet(text='way, way more money and time going into', start=1050.72, duration=4.079), FetchedTranscriptSnippet(text='the inference side, and Nvidia selling', start=1052.64, duration=3.68), FetchedTranscriptSnippet(text='chips for inference will stop making', start=1054.799, duration=3.601), FetchedTranscriptSnippet(text='sense very quickly with basic economics', start=1056.32, duration=5.52), FetchedTranscriptSnippet(text='of scale. But until then, I suspect, and', start=1058.4, duration=5.279), FetchedTranscriptSnippet(text='again, this is not financial advice, I', start=1061.84, duration=3.44), FetchedTranscriptSnippet(text='would expect Nvidia to stay pretty close', start=1063.679, duration=4.0), FetchedTranscriptSnippet(text='to the top for a while as the market', start=1065.28, duration=5.6), FetchedTranscriptSnippet(text='slowly realizes that TSMC is the company', start=1067.679, duration=5.041), FetchedTranscriptSnippet(text='actually producing the value. And more', start=1070.88, duration=4.0), FetchedTranscriptSnippet(text='importantly, the novelty that makes', start=1072.72, duration=4.48), FetchedTranscriptSnippet(text='Nvidia so high up here is something that', start=1074.88, duration=3.76), FetchedTranscriptSnippet(text=\"they aren't necessarily the best\", start=1077.2, duration=2.96), FetchedTranscriptSnippet(text=\"solution for. I think I've said all I\", start=1078.64, duration=3.279), FetchedTranscriptSnippet(text=\"have to here. It's always fun to rage at\", start=1080.16, duration=4.08), FetchedTranscriptSnippet(text='Nvidia as a lifetime gamer that has a', start=1081.919, duration=3.841), FetchedTranscriptSnippet(text='lot of opinions about the company, but', start=1084.24, duration=2.88), FetchedTranscriptSnippet(text=\"in the end, I'm just excited to see\", start=1085.76, duration=2.72), FetchedTranscriptSnippet(text='competition happening and for inference', start=1087.12, duration=3.2), FetchedTranscriptSnippet(text='to get faster. I want these models to', start=1088.48, duration=3.92), FetchedTranscriptSnippet(text='run as fast as we can possibly have them', start=1090.32, duration=3.52), FetchedTranscriptSnippet(text='because that makes them easier to use', start=1092.4, duration=2.8), FetchedTranscriptSnippet(text='and more powerful in our day-to-day', start=1093.84, duration=3.28), FetchedTranscriptSnippet(text=\"work. I'm excited to run things like\", start=1095.2, duration=4.16), FetchedTranscriptSnippet(text='codecs on 3,000 tokens per second', start=1097.12, duration=4.0), FetchedTranscriptSnippet(text='instead of the measly 30 to 40 that we', start=1099.36, duration=3.04), FetchedTranscriptSnippet(text='get today. Let me know what you guys', start=1101.12, duration=5.36), FetchedTranscriptSnippet(text='think. And until next time, peace nerds.', start=1102.4, duration=4.08)], video_id='J8lxHyQmcaI', language='English (auto-generated)', language_code='en', is_generated=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5482fb13-2868-42fb-843b-def54e1bb3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join([entry.text for entry in transcript])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c514388-265a-46e9-9474-51c77194853f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Did you know that Nvidia is the most valuable company in the world? I mean, it makes sense, right? All of these huge AI companies are relying on them fully in order to do the AI stuff that we all expect them to do. That\\'s why Nvidia\\'s value is comparable to that of silver. Yes, all of the silver in the world is comparable to the value of Nvidia, just one company that makes chips for gamers. And now those same chips turn out to be really good for AI stuff, which is why everybody is using them. So, does Anthropic, oh, Anthropic\\'s moving to Google\\'s TPUs? Well, that\\'s fine. There\\'s plenty of other companies that aren\\'t doing that like OpenAI. Oh, OpenAI is partnering with Cerebrris, the chip company. Well, at least there\\'s Meta, right? Oh, Google\\'s working to erode Nvidia\\'s software advantage with Meta\\'s help. Google\\'s going to be giving TPUs to Meta. Huh. Very interesting. In fact, things have gotten so crazy that even Nvidia is investing in alternatives to Nvidia, like Grock, who they just paid some crazy number. It\\'s currently estimated around $20 billion to license Grock\\'s technology and pull its founder and some other people over to bring what Grock does to Nvidia because it turns out GPUs might not actually be the best solution for AI going forward. It\\'s crazy to think that the literal most valuable company in the world might be selling a type of chip that stops being relevant in the next few years, if not even few months. And I have a lot to say about it. But you know what\\'s likely going to stay valuable? Today\\'s sponsor. One of the biggest hiccups I\\'ve seen for big companies adopting AI tools is the change in the mindset and flow. A lot of their stuff just isn\\'t built for moving this fast. In particular, their CI. How great is it to file 10 PRs a day if those PRs take 40 minutes each to build? Be a lot better if they took under a minute, right? That sounds impossible though. Unless you\\'re using today\\'s sponsor, Depot. These guys will make your builds absurdly fast. Post Hog got 30 times faster. Their builds went from 138 minutes down to 4 and a half. That\\'s hilariously faster. Even the worst case with Zed still saw a 1.4x increase. Most saw closer to 3 to 20x though with Mastadon hitting 19x from 46 minutes to 2 1/2. I like how Post Hog put this best. Around here, we say Post Hog ships weirdly fast. And you can\\'t say Post Hog ships weirdly fast if you\\'re waiting for an hour and 45 minutes for it to ship. I personally experienced this when we were trying to ship changes on T3 chat for our wrapped feature and Post Hog was shipping stuff for us. They got things shipped during a holiday week in literally 10 minutes because their builds finished almost instantly because they moved depot. Depot unblocked features for me. That\\'s something I can\\'t say about very many sponsors. It\\'s time to stop wasting time. Fix your builds at soyv.link/depo. So, let\\'s talk a bit about why Nvidia\\'s kind of doomed. In order to understand this, we need to first understand how we got here in the first place. Why is it that the company that made graphics cards for our gaming PCs suddenly became the most valuable company in the world? I could go way too deep on the weird history of Nvidia as a hardware partner from how they [\\xa0__\\xa0] over Apple, so many other things. I just I\\'m a nerd about this. I know way too much. I have been an Nvidia hater for the better part of like 15 or so years now because they made my life as a PC builder way harder. They made Apple\\'s lives way harder. They Nvidia\\'s just been a really bad player in the market for a long, long time. But Nvidia did have one thing, the best GPUs. It turns out making GPUs is hard. That\\'s why so many companies have been struggling to get into it themselves. Intel started their own GPU division a few years ago in order to try and catch up with Nvidia and AMD and they have struggled immensely. AMD tried and failed as well and instead chose to buy out ATI which was a company that was competing pretty close with Nvidia at the time, the time being like 20 years ago and since then has been folded fully into AMD as their graphics division. And those graphics chips are the ones being used in most home consoles today. Things like the Xbox and the PlayStation because both Sony and Microsoft have moved as far away from Nvidia as possible because they\\'ve had so many problems with them. And funny enough, the only one still betting on Nvidia for consoles is Nintendo because they inked some crazy private deal in order to use all of Nvidia\\'s failed ARM chips that they were trying to sell for tablets, trying to move those to the Switch in hopes of finding a market for it. And that went better than anyone would have expected. So Nvidia\\'s only console sales, only gaming sales right now are to Nintendo of all companies. But for the most part, Nvidia has pissed off all of their partners over the last 20 years to the point where very few of them still choose to rely heavily on Nvidia in the hardware sales and distribution space. And the reason they get away with it is again making GPUs is really, really hard. It\\'s so hard that Nvidia doesn\\'t even do it themselves. So what the hell makes Nvidia so valuable then if they\\'re not making the GPUs? company that\\'s actually making the chips and the dyes and the silicon that goes into Nvidia\\'s GPUs is a company named TSMC, Taiwan\\'s semiconductor manufacturing company. These guys manufacture the silicon for all of the best chips in the world. There are other companies that make chips, but none of them make chips as small, refined, and powerful as TSMC. That\\'s why Apple relies on them heavily for all of their chips. The reason the M series Maxs and the iPhones and iPads in general are so performant is because Apple made a bet on TSMC early as their silicon manufacturing partner. And more and more companies have had to move over as well, including crazy enough companies like Intel that historically have owned their own manufacturing. TSMC is in my opinion the company that is actually most valuable by far across all of this because without TSMC the performance that we expect from Nvidia, from AMD, from Intel, from Apple, from all these things is no longer possible. This company is what the next world war will probably start around. As crazy as that sounds, whoever controls TSMC kind of controls how powerful chips are for the rest of the world. But TSMC is just taking a blueprint and constructing it. Those blueprints have to come from companies. Those specs, those plans, those tolerances, those expectations, the SDKs and platforms around them, the thing that you\\'re actually shipping to a user. TSMC isn\\'t shipping a chip to a user. TSMC is taking in a blueprint, printing it onto an impossibly small die, and then sending that to a company like Apple or Nvidia to do what they want to with. And Nvidia has really, really good architecture for doing GPUs through processes being developed by TSMC. Nvidia comes up with crazy ways to do compute with silicon that they then forward to TSMC as a plan that gets manufactured and then given back to Nvidia. And part of the agreement is that TSMC can\\'t keep those blueprints, can\\'t reuse or sell those blueprints or any techniques that Nvidia makes up or discovers, which means a lot of the things that make Nvidia\\'s chips so good at generic crazy math processing [\\xa0__\\xa0] is stuff that TSMC knows about but can\\'t reuse or resell. And all of the things that have leaked are so heavily patented that Nvidia will sue your [\\xa0__\\xa0] life out of your soul if you try to copy them. And the reason for this is relatively simple. Nvidia\\'s GPUs are really good at generic compute BS, especially all the fancy vector math stuff and matrix transformations and the things you\\'ll hear about on other YouTube channels that go way deeper in the math. The NVIDIA chips were built to handle those types of things because they were built to handle lots of pixels on a screen. If your processor has four cores and you have to process 1920x 1080 pixels, that\\'s 2 million pixels you have to process every frame. That\\'s 16 milliseconds of time. Imagine processing over 2 million pixels on 4 to 8 cores in 16 milliseconds. Good luck. Good luck. This is why GPUs are so powerful. They have thousands of these much smaller, dumber cores effectively that are built to do this large math transformation stuff. and it can handle these types of workloads much more easily, similar to how they handled things like mining cryptocurrencies. I\\'m probably gonna date myself a bunch here, but when I was in high school, my favorite thing about having a nice GPU is that it was a free source of income because I could use it to mine Bitcoin because Bitcoin mining was a complex enough math problem that a powerful GPU could solve and you would make some money as you powered the network of Bitcoin. It was so powerful and it was so useful that people started looking for ways to optimize the math because the GPU is really good at these types of generic problems. But if you\\'re doing the exact same thing over and over again, the GPU being so generic stops being as beneficial. And this is why AS6 started to become popular. And ASIC, as Google summarizes for us here, thank you. Probably ran on an ASIC, funny enough, is an application specific integrated circuit. They were commonly used for Bitcoin specifically because the Bitcoin math could be optimized further if you made a purpose-built chip to just do that one piece of math. And very quickly, AS6 took over in the Bitcoin mining world to the point where if you were using a GPU, you were losing money because your power bill was greater than what you would make back versus an ASIC minor which was so much more optimized that it was more capable of getting more blocks broken in faster times and using less power. This is the thing that we are here to talk about. Not Bitcoin AS6 but the idea of application specific integrations in general on chips. Cerebras is the most prominent company in this space. The space that we are talking about here is accelerator hardware chips that can be given these workloads and actually perform them and generate results. a chip that can traverse this gigantic pile of parameters that are often hundreds of gigs large, which is the model itself, that it can then use and pull in this pile of text that a user generated or is your chat history or whatever, and combine those two things to figure out which token is most likely to be next. By using all of the parameters and its giant map, adding in the math it calculates off of the text you put in to point it towards what parameter is most likely to be next. It\\'s this giant web of vectors pointing to and from each other that is hard math to calculate, but it turns out you can optimize chips to be way better at it. GPUs are better than almost anything else that exists in the traditional world at this. And since a lot of workloads for training tend to need more competence and capability in what you can do, GPUs are still the chip of choice for training. But when you actually want to run the model once it\\'s done being baked, those same chips are nowhere near as efficient as tailor-made solutions. The other interesting thing here is the companies you think of most immediately when you think of AI, you know, the open AIS and the anthropics and the metas of the world, those companies don\\'t make their own accelerator hardware. They are all just using chips. They buy from other companies, mostly from Nvidia. But there are some investments happening in accelerator hardware. most notably Google, which is the only company that covers everything from the apps you use with AI to the models to the place that you host the models to the hardware the models run on. Google\\'s one of the only companies that\\'s competing in all of those spaces and fighting any success with it at all. Even Nvidia doesn\\'t really let you rent GPUs from the cloud. They bought a company that does it. They barely maintain it. If you want to use a bunch of Nvidia GPUs, you better go buy them from Nvidia or find somebody else who already has. So Nvidia has historically been the default option that all these other companies rely on when they\\'re trying to do inference training and everything else. But that is a wedge that other companies noticed existed. Companies like Grock, Cerebrus, and SANA. All three of these companies know that this can be optimized better, especially the actual inference side based on what they\\'ve seen in the past with things like, you know, Bitcoin AS6. There\\'s obviously opportunity here to make things that are faster for doing inference. If you want proof of this, look no further than Open Router. If you\\'re not familiar, Open Router lets you route your LLM traffic across different places to make it easier to change out what model you\\'re using, what platform is hosting the model, things like that. So, it\\'s really easy to take an open weight model like GPOSS120B and change where you\\'re actually running it because you just change the string or let them do it for you. Companies like Deep Infra, which are using traditional Nvidia GPUs, can run this model at around 60 tokens per second. on my laptop, on my MacBook, I could run the same model at 80 tokens per second. But if you scroll down to a company like Grock, which again makes their own chips for this purpose, you go from 60 to 80 TPS up to 360 tokens per second or with Cerebrris all the way up to 702 TPS. That\\'s a 10x difference. That means it\\'s running the model 10 times faster. Insane. There are models where Cerebras can pull 3,000 TPS if the optimizations are right and the model is built to work well with the architecture of their chips. One of the most common complaints with OpenAI models right now, especially models like GPT 5.2 codecs, is that they are really smart, but they\\'re really slow and just not as pleasant to use as a result. Which is why this partnership is really exciting and why the first thing Sam Alman had to say about it was very fast codecs coming. Yeah, this is a bet to let them make the models way faster and also theoretically speaking, free up some of their NVIDIA GPUs that were being used for this inference. So, they could use those GPUs for training instead. Every GPU you\\'re using for training is a GPU you can\\'t use for inference. So, if they move inference off GPUs, they have more of them available for doing training work. And when you look into a company like Cerebras, you see just how hard they\\'re going to make all of this happen. They make gigantic chips on one hand because they want to put more things on them, but also because they don\\'t have access to the same manufacturing that Nvidia does for TSMC. So, their actual die sizes have to be larger as well. That said, their wafers can do crazy inference. It\\'s wild to look at this and see how gigantic the chips are. The problem with manufacturing chips that are this big is that having all of the pieces you put into it work is likely not going to happen. The bigger the chip is and the more dyes you put on it, the higher chance that some of those are failing, which is one of the big things they\\'ve had to innovate in a lot. How do you reduce the failure rates low enough that you can actually make a chip this big without having a bunch of the dies dead on it on arrival? Also, notice how little information they\\'re putting on the page here. That is a choice. These companies are all hiding the absolute [\\xa0__\\xa0] out of everything that they are doing. Cerebras, Grock, Sonova, Nvidia, AMD, Intel, none of these companies are sharing any details about how they make these things. This is the type of information that like you need to sign 15 NDAs, promise your firstborn child, and then wear a top tobottom gown that is static proof, and go through a room to be sanitized before you\\'re even allowed inside of the facility. The amount of secrecy and privacy around these things makes Apple look like an open- source company. It\\'s kind of nuts, but there\\'s a reason for it. There\\'s a very expensive reason for it. Nvidia is worth $4.5 trillion. If the secrets that make their chip so good become public information, Nvidia is no longer worth $4.5 trillion. And Nvidia knows this and is scared of this, which is why they spent 20 billion of those 4.5 trillion to do a partnership with one of these chip companies, Grock. Not Grock with a K. Grock with a Q. Grock with a Q is one of the companies building these chips. They refer to their chips as the LPUs. These chips are built for doing inference really, really performantly, just like the other ones we\\'re talking about. No wasted operations, no unpredictable delays, every cycle accounted for. They also integrate the memory on chip because then things end up being way faster and you can squeeze way more RAM on to fit bigger models. They\\'re power efficient. They\\'re on these gigantic racks that they put wherever they can in the world. They also often have to build their own SDKs because remember you don\\'t get access to cool things like CUDA anymore, the standard for building GPU optimized work when you have a chip that\\'s not a GPU. So that not only are these companies rethinking the actual chips that we\\'re running everything on, they also have to rethink the SDKs in the software that we\\'re building on top of them. And often this is a back and forth where a company like Grock has to deeply analyze how a model like Llama works, what parts of the GPU it\\'s hitting, and then take those things and optimize them to Helen back to squeeze into a custom chip. And that back and forth is crazy. Sometimes a new model drops and it doesn\\'t fit well on a Grock chip. And now they have to go back to the drawing board and make modifications both to the model and to the chip to try and make them mesh better. And since everything\\'s still trained on Nvidia, everything\\'s still largely built to be run on Nvidia. So yeah, it turns out when you make a chip for a specific purpose, you can outperform chips that are made for more generic work. And the only way Nvidia\\'s current architecture would keep them as number one is if it turns out by some weird divine intervention that GPU architecture is just magically the exact architecture that makes the most sense for doing AI work. In order to beat Nvidia, you have to replace all of the things that make Nvidia great. You have to have all of the things that they do in a generic way accessible in other places. You have to handle the fact that everything\\'s built around CUDA and crazy tools around it just aren\\'t going to work on these other things yet. You have to be prepared to fight on all of those levels. But there\\'s a lot of companies that are prepared for that fight and are pushing hard. But it\\'s important to know how long that takes as well. When TSMC wants to spin up new manufacturing, that doesn\\'t happen in months. That doesn\\'t happen in a year. It takes five plus years for TSMC to say, \"Okay, we have this process. We want to implement it. We\\'re going to build a new factory for it.\" 5 to 10 years. That\\'s also why the chip shortages are happening now because the demand went up. And it takes 5 to 10 years for the manufacturing to catch up. That\\'s also why we\\'re starting to see these companies like Grock and Cerebras finally really getting competitive because it\\'s been about 5 to 10 years since they started. But in the end, margins always win. And the margins Nvidia has right now are far too high when their chips aren\\'t as optimized as they could be. Right now, we\\'re putting a lot of money into training and inference, but over time, if the AI bubble continues to grow, we\\'ll have way, way more money and time going into the inference side, and Nvidia selling chips for inference will stop making sense very quickly with basic economics of scale. But until then, I suspect, and again, this is not financial advice, I would expect Nvidia to stay pretty close to the top for a while as the market slowly realizes that TSMC is the company actually producing the value. And more importantly, the novelty that makes Nvidia so high up here is something that they aren\\'t necessarily the best solution for. I think I\\'ve said all I have to here. It\\'s always fun to rage at Nvidia as a lifetime gamer that has a lot of opinions about the company, but in the end, I\\'m just excited to see competition happening and for inference to get faster. I want these models to run as fast as we can possibly have them because that makes them easier to use and more powerful in our day-to-day work. I\\'m excited to run things like codecs on 3,000 tokens per second instead of the measly 30 to 40 that we get today. Let me know what you guys think. And until next time, peace nerds.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20784"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248a534-5865-4890-a24e-f844e258ddec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not fetch transcript for video J8lxHyQmcaI: 'FetchedTranscriptSnippet' object is not subscriptable\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Akaash\\Desktop\\D_Drive\\Project\\AI_NewsLetter\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3709: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"Quick manual test for fetching a transcript.\"\"\"\n",
    "    video_id = \"J8lxHyQmcaI\"  # sample video id\n",
    "    fetcher = TranscriptFetcher()\n",
    "    transcript = fetcher.fetch_transcript(video_id)\n",
    "    if transcript:\n",
    "        print(json.dumps({\"video_id\": video_id, \"excerpt\": transcript[:500]}, indent=2))\n",
    "    else:\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e9ab7-1d8a-4860-a240-5fe494d7658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "    TRANSCRIPT_API_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TRANSCRIPT_API_AVAILABLE = False\n",
    "\n",
    "\n",
    "class TranscriptFetcher:\n",
    "    \"\"\"Fetches and cleans YouTube video transcripts.\"\"\"\n",
    "\n",
    "    # Common filler words/sounds to remove\n",
    "    FILLER_WORDS = {\n",
    "        \"um\",\n",
    "        \"uh\",\n",
    "        \"like\",\n",
    "        \"you know\",\n",
    "        \"basically\",\n",
    "        \"literally\",\n",
    "        \"actually\",\n",
    "        \"honestly\",\n",
    "        \"right\",\n",
    "        \"so\",\n",
    "        \"yeah\",\n",
    "        \"okay\",\n",
    "        \"alright\",\n",
    "        \"well\",\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize TranscriptFetcher.\"\"\"\n",
    "        if not TRANSCRIPT_API_AVAILABLE:\n",
    "            raise RuntimeError(\n",
    "                \"youtube-transcript-api not installed. Install with: pip install youtube-transcript-api\"\n",
    "            )\n",
    "\n",
    "    def fetch_transcript(self, video_id: str, languages: list = None) -> str | None:\n",
    "        \"\"\"\n",
    "        Fetch transcript for a YouTube video.\n",
    "\n",
    "        Args:\n",
    "            video_id: YouTube video ID\n",
    "            languages: List of language codes to try (e.g., ['en', 'es'])\n",
    "\n",
    "        Returns:\n",
    "            Transcript text or None if not available\n",
    "        \"\"\"\n",
    "        if not TRANSCRIPT_API_AVAILABLE:\n",
    "            raise RuntimeError(\"youtube-transcript-api not installed\")\n",
    "\n",
    "        if languages is None:\n",
    "            languages = [\"en\"]\n",
    "\n",
    "        try:\n",
    "            \n",
    "            # transcript = YouTubeTranscriptApi.fetch(video_id, languages=languages)\n",
    "            ytt_api = YouTubeTranscriptApi()\n",
    "            transcript = ytt_api.fetch(video_id, languages=languages)\n",
    "            # Merge transcript entries into continuous text\n",
    "            text = \" \".join([entry.text for entry in transcript])\n",
    "            return text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch transcript for video {video_id}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def clean_transcript(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Clean raw transcript text.\n",
    "\n",
    "        Operations:\n",
    "        - Remove timestamps and brackets\n",
    "        - Normalize spaces\n",
    "        - Remove filler words at start of sentences\n",
    "        - Remove repeated punctuation\n",
    "\n",
    "        Args:\n",
    "            text: Raw transcript text\n",
    "\n",
    "        Returns:\n",
    "            Cleaned text\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "\n",
    "        # Remove bracketed content (like [Music], [Applause])\n",
    "        text = re.sub(r\"\\[.*?\\]\", \"\", text)\n",
    "\n",
    "        # Remove multiple spaces\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "        # Remove repeated punctuation\n",
    "        text = re.sub(r\"\\.{2,}\", \".\", text)\n",
    "        text = re.sub(r\"!{2,}\", \"!\", text)\n",
    "        text = re.sub(r\"\\?{2,}\", \"?\", text)\n",
    "\n",
    "        # Clean up filler words at the beginning of sentences\n",
    "        text = self._remove_filler_words(text)\n",
    "\n",
    "        # Normalize spacing around punctuation\n",
    "        text = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", text)\n",
    "        text = re.sub(r\"([.,!?;:])\\s*([a-zA-Z])\", r\"\\1 \\2\", text)\n",
    "\n",
    "        return text.strip()\n",
    "\n",
    "    def _remove_filler_words(self, text: str) -> str:\n",
    "        \"\"\"Remove filler words at the beginning of sentences.\"\"\"\n",
    "        sentences = text.split(\". \")\n",
    "        cleaned_sentences = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            words = sentence.split()\n",
    "            # Remove leading filler words\n",
    "            while words and words[0].lower().rstrip(\",\") in self.FILLER_WORDS:\n",
    "                words.pop(0)\n",
    "\n",
    "            if words:\n",
    "                cleaned_sentences.append(\" \".join(words))\n",
    "\n",
    "        return \". \".join(cleaned_sentences)\n",
    "\n",
    "    def fetch_and_clean(\n",
    "        self, video_id: str, title: str, link: str, languages: list = None\n",
    "    ) -> Dict[str, Any] | None:\n",
    "        \"\"\"\n",
    "        Fetch and clean transcript in one call.\n",
    "\n",
    "        Args:\n",
    "            video_id: YouTube video ID\n",
    "            title: Video title\n",
    "            link: Video link\n",
    "            languages: Language preferences\n",
    "\n",
    "        Returns:\n",
    "            Dict with video_id, title, clean_text, link or None\n",
    "        \"\"\"\n",
    "        raw_text = self.fetch_transcript(video_id, languages)\n",
    "\n",
    "        if raw_text is None:\n",
    "            return None\n",
    "\n",
    "        clean_text = self.clean_transcript(raw_text)\n",
    "\n",
    "        return {\n",
    "            \"video_id\": video_id,\n",
    "            \"title\": title,\n",
    "            \"clean_text\": clean_text,\n",
    "            \"link\": link,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d95e7-30a9-4065-ad46-d54d1f2a1ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"video_id\": \"J8lxHyQmcaI\",\n",
      "  \"excerpt\": \"Did you know that Nvidia is the most valuable company in the world? I mean, it makes sense, right? All of these huge AI companies are relying on them fully in order to do the AI stuff that we all expect them to do. That's why Nvidia's value is comparable to that of silver. Yes, all of the silver in the world is comparable to the value of Nvidia, just one company that makes chips for gamers. And now those same chips turn out to be really good for AI stuff, which is why everybody is using them. So\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"Quick manual test for fetching a transcript.\"\"\"\n",
    "    video_id = \"J8lxHyQmcaI\"  # sample video id\n",
    "    fetcher = TranscriptFetcher()\n",
    "    transcript = fetcher.fetch_transcript(video_id)\n",
    "    if transcript:\n",
    "        print(json.dumps({\"video_id\": video_id, \"excerpt\": transcript[:500]}, indent=2))\n",
    "    else:\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556ad71-24a9-4fa7-b351-719ab5efd097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://www.youtube.com/@t3dotgg -> Channel ID: UCbRP3c757lWg9M-U7TyEkXA\n",
      "URL: https://www.youtube.com/@theothrowaways -> Channel ID: UCuJ0a6mGprfuF0CTp04rGjQ\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "class YouTubeChannelResolver:\n",
    "    # This matches ONLY the owner channel id\n",
    "    CHANNEL_ID_REGEX = re.compile(r'\"externalId\":\"(UC[a-zA-Z0-9_-]{22})\"')\n",
    "\n",
    "    def __init__(self, timeout=10):\n",
    "        self.timeout = timeout\n",
    "\n",
    "    def get_channel_id(self, channel_url: str) -> str:\n",
    "        \"\"\"\n",
    "        Takes any YouTube channel URL and returns permanent owner channel_id (UC...).\n",
    "        Raises ValueError if not found.\n",
    "        \"\"\"\n",
    "\n",
    "        # Normalize URL\n",
    "        if not channel_url.startswith(\"http\"):\n",
    "            channel_url = \"https://\" + channel_url\n",
    "\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0\"  # avoid bot blocking\n",
    "        }\n",
    "\n",
    "        response = requests.get(channel_url, headers=headers, timeout=self.timeout)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        html = response.text\n",
    "\n",
    "        match = self.CHANNEL_ID_REGEX.search(html)\n",
    "        if not match:\n",
    "            raise ValueError(\"Owner channel ID not found in page source\")\n",
    "\n",
    "        return match.group(1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resolver = YouTubeChannelResolver()\n",
    "\n",
    "    test_urls = [\n",
    "        \"https://www.youtube.com/@t3dotgg\",\n",
    "        \"https://www.youtube.com/@theothrowaways\"\n",
    "    ]\n",
    "\n",
    "    for url in test_urls:\n",
    "        try:\n",
    "            channel_id = resolver.get_channel_id(url)\n",
    "            print(f\"URL: {url} -> Channel ID: {channel_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to resolve {url}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
